{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all necessary libraries to get more structured data \n",
    "import time\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException, TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all necessary libraries to get more structured data \n",
    "import time\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException, TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "#from webdriver_manager.chrome import ChromeDriverManager\n",
    "driver=webdriver.Chrome() \n",
    "website=\"https://www.dealstreetasia.com/section/venture-capital\"  \n",
    "driver.get(website)\n",
    "\n",
    "# Define the exact date limit (2 months ago)\n",
    "two_months_ago = datetime.now() - timedelta(days=60)\n",
    "\n",
    "# Create CSV file for writing\n",
    "csv_filename = \"full_scraped_articles.csv\"\n",
    "with open(csv_filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Source\", \"Date\", \"Article Content\", \"URL\"])  # CSV Header\n",
    "\n",
    "    # Function to parse and reformat date\n",
    "    def parse_and_format_date(date_str):\n",
    "        try:\n",
    "            parsed_date = datetime.strptime(date_str, \"%d %B, %Y\")  # Convert '14 January, 2025'\n",
    "            return parsed_date.strftime(\"%d ,%m, %Y\")  # Format to '14 ,01, 2025'\n",
    "        except ValueError:\n",
    "            return None  # Handle unexpected formats\n",
    "\n",
    "    last_article_old = False  # Stop when an article older than 2 months is found\n",
    "    last_scraped_index = 0  # Keep track of last scraped article index\n",
    "\n",
    "    while not last_article_old:\n",
    "        # Step 1: Extract all current article links\n",
    "        articles = driver.find_elements(By.XPATH, '//*[@id=\"archive-wrapper\"]/div[4]/div[1]/div/div')\n",
    "        article_links = [article.find_element(By.XPATH, './div[1]/a').get_attribute('href') for article in articles]\n",
    "\n",
    "        # Start from the last scraped index (continue from where we left off)\n",
    "        for i in range(last_scraped_index, len(article_links)):\n",
    "            link = article_links[i]\n",
    "            driver.get(link)\n",
    "            time.sleep(2)  # Wait for article page to load\n",
    "\n",
    "            try:\n",
    "                # Extract article details\n",
    "                title = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/h1').text.strip()\n",
    "                source = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[1]/div/div[1]/span/a').text.strip()\n",
    "                date_text = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[1]/div/div[1]/p').text.strip()\n",
    "                body = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[2]/div[1]/article').text.strip().replace(\"\\n\", \" \")\n",
    "\n",
    "                # Convert date and compare with the 2-month limit\n",
    "                formatted_date = parse_and_format_date(date_text)\n",
    "                article_date = datetime.strptime(formatted_date, \"%d ,%m, %Y\") if formatted_date else None\n",
    "\n",
    "                if article_date and article_date < two_months_ago:\n",
    "                    print(f\"⏹️ Stopping: Found an article older than 2 months ({formatted_date})\")\n",
    "                    last_article_old = True\n",
    "                    break  # Stop processing further\n",
    "\n",
    "                # Save to CSV\n",
    "                writer.writerow([title, source, formatted_date, body, link])\n",
    "                print(f\"Saved article: {title} - {formatted_date}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\" Error extracting article data from {link}: {e}\")\n",
    "\n",
    "            # Update last scraped index\n",
    "            last_scraped_index = i + 1\n",
    "\n",
    "            # Go back to the main page to scrape the next article\n",
    "            driver.back()\n",
    "            time.sleep(2)  # Wait for the main page to reload\n",
    "\n",
    "        if last_article_old:\n",
    "            break  # Stop clicking \"More\" if we found an old article\n",
    "\n",
    "        # Step 2: Click the \"More\" button to load more articles\n",
    "        try:\n",
    "            more_button = driver.find_element(By.XPATH, '//*[@id=\"archive-wrapper\"]/div[5]/div/button')\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", more_button)\n",
    "            time.sleep(1)\n",
    "            driver.execute_script(\"arguments[0].click();\", more_button)\n",
    "            time.sleep(5)  # Wait for new articles to load\n",
    "\n",
    "            # Update last_scraped_index to continue from where we left off\n",
    "            last_scraped_index = len(article_links)\n",
    "\n",
    "        except (NoSuchElementException, ElementClickInterceptedException):\n",
    "            print(\" No 'More' button found or can't be clicked. Stopping.\")\n",
    "            break  # Stop if the button is missing or can't be clicked\n",
    "\n",
    "print(f\"\\n Scraping complete! Data saved to {csv_filename}\")\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "website=\"https://www.dealstreetasia.com/section/venture-capital\"  \n",
    "driver.get(website)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "found out all requirement paths to construct the scraping scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# //*[@id=\"archive-wrapper\"]/div[4]/div[1]/div/div[1]\n",
    "# //*[@id=\"archive-wrapper\"]/div[4]/div[1]/div/div[1]/div[1]/a ...link adress\n",
    "# //*[@id=\"disable-copy\"]/h1...title\n",
    "# //*[@id=\"disable-copy\"]/div[2]/div[1]/div/div[1]/span/a ...source\n",
    "# //*[@id=\"disable-copy\"]/div[2]/div[1]/div/div[1]/p....date\n",
    "# //*[@id=\"disable-copy\"]/div[2]/div[2]/div[1]/article...body \n",
    "# //*[@id=\"archive-wrapper\"]/div[4]/div[1]/div/div[2]\n",
    "# //*[@id=\"disable-copy\"]/h1 ...title\n",
    "# //*[@id=\"disable-copy\"]/div[2]/div[1]/div/div[1]/p ...date\n",
    "# //*[@id=\"disable-copy\"]/div[2]/div[2]/div[1]/article...body\n",
    "# //*[@id=\"disable-copy\"]/div[2]/div[1]/div/div[1]/span/a\n",
    "# //*[@id=\"archive-wrapper\"]/div[4]/div[1]/div/div[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the first page that the give path are properly work or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: India's Cornerstone Ventures hits first close of second fund at around $40m\n",
      "Source: Vibhuti Sharma\n",
      "Date: 15 January, 2025\n",
      "Article: Indian SaaS-focused venture capital firm Cornerstone Ventures on Wednesday said it has hit the first close of its $200-million second investment vehicle at around $40 million.\n",
      "The vehicle, launched in April last year, raised capital from domestic investors, including HNIs, family offices, corporates, and other institutions.\n",
      "Founded by former Reliance executives Rajiv Vaishnav and Abhishek Prasad, Cornerstone expects to make the final close of the fund by December 2025.\n",
      "Cornerstone raised $50 mil...\n",
      "--------------------------------------------------------------------------------\n",
      "Title: DEG commits to invest $40m in Jungle Ventures's fifth vehicle\n",
      "Source: Quynh Nguyen\n",
      "Date: 15 January, 2025\n",
      "Article: DEG, the investment arm of German state-owned development bank KfW, has committed to investing $40 million in Jungle Ventures‘s fifth fund, which has a targeted corpus of $500 million, according to a disclosure....\n",
      "--------------------------------------------------------------------------------\n",
      "Title: Indonesian fintech startup Skor Technologies secures $6.2m funding led by Argor Capital\n",
      "Source: Marsya Nabila\n",
      "Date: 14 January, 2025\n",
      "Article: Skor Technologies, the parent company of Indonesia-based startup Skorlife and Skorcard credit card, has raised $6.2 million in a pre-Series A funding round, led by Southeast Asia-focused venture capital firm Argor Capital, according to an announcement on Tuesday....\n",
      "--------------------------------------------------------------------------------\n",
      "Title: Indonesian AI startup Bythen secures $5m funding led by Vector Inc, Skystar Capital\n",
      "Source: Marsya Nabila\n",
      "Date: 14 January, 2025\n",
      "Article: Bythen, an Indonesian AI startup for virtual creators, has announced a $5-million seed financing round led by Japan’s Vector Inc. and Indonesia’s VC Skystar Capital, according to an announcement on Tuesday....\n",
      "--------------------------------------------------------------------------------\n",
      "Title: India's Boba tea and Korean fusion food brand Boba Bhai bags funding\n",
      "Source: Vibhuti Sharma\n",
      "Date: 13 January, 2025\n",
      "Article: India’s boba tea and Korean fusion food brand Boba Bhai on Monday said it has raised Rs 30 crore ($3.5 million) in a Series A round led by 8i Ventures, aiming to expand to new cities and capture the Gen Z and Millennial market.\n",
      "The round also saw participation from Titan Capital Winners Fund, Global Growth Capital, DEVC and existing investors.\n",
      "Launched in October 2023, Boba Bhai claims to process over 80,000 monthly orders and establish a presence in 42 outlets across nine cities, including Beng...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Wait for the page to load\n",
    "time.sleep(3)  # Adjust based on page load time\n",
    "\n",
    "# Extract article links\n",
    "articles = driver.find_elements(By.XPATH, '//*[@id=\"archive-wrapper\"]/div[4]/div[1]/div/div')\n",
    "article_links = [article.find_element(By.XPATH, './div[1]/a').get_attribute('href') for article in articles]\n",
    "\n",
    "# Loop through each article link and extract details\n",
    "for link in article_links:\n",
    "    driver.get(link)\n",
    "    time.sleep(4)  # Ensure the page loads before extracting data\n",
    "\n",
    "    try:\n",
    "        # Extract article details\n",
    "        title = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/h1').text\n",
    "        source = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[1]/div/div[1]/span/a').text\n",
    "        date = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[1]/div/div[1]/p').text\n",
    "        body = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[2]/div[1]/article').text\n",
    "\n",
    "        # Print extracted data\n",
    "        print(f\"Title: {title}\")\n",
    "        print(f\"Source: {source}\")\n",
    "        print(f\"Date: {date}\")\n",
    "        print(f\"Article: {body[:500]}...\")  # Print first 500 characters\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting article data from {link}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check up the scripts and view the fomat of the first page data to preceding to the next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: India's Cornerstone Ventures hits first close of second fund at around $40m\n",
      "Saved article: DEG commits to invest $40m in Jungle Ventures's fifth vehicle\n",
      "Saved article: Indonesian fintech startup Skor Technologies secures $6.2m funding led by Argor Capital\n",
      "Saved article: Indonesian AI startup Bythen secures $5m funding led by Vector Inc, Skystar Capital\n",
      "Saved article: India's Boba tea and Korean fusion food brand Boba Bhai bags funding\n",
      "\n",
      "Scraping complete! Data saved to scraped_articles.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "# Wait for the page to load\n",
    "time.sleep(3)  # Adjust based on page load time\n",
    "\n",
    "# Extract article links\n",
    "articles = driver.find_elements(By.XPATH, '//*[@id=\"archive-wrapper\"]/div[4]/div[1]/div/div')\n",
    "article_links = [article.find_element(By.XPATH, './div[1]/a').get_attribute('href') for article in articles]\n",
    "\n",
    "# Create and open a CSV file for writing\n",
    "csv_filename = \"scraped_articles.csv\"\n",
    "with open(csv_filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Source\", \"Date\", \"Article Content\", \"URL\"])  # Added URL column\n",
    "\n",
    "    # Loop through each article link and extract details\n",
    "    for link in article_links:\n",
    "        driver.get(link)\n",
    "        time.sleep(4)  # Ensure the page loads before extracting data\n",
    "\n",
    "        try:\n",
    "            # Extract article details\n",
    "            title = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/h1').text.strip()\n",
    "            source = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[1]/div/div[1]/span/a').text.strip()\n",
    "            date = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[1]/div/div[1]/p').text.strip()\n",
    "            body = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[2]/div[1]/article').text.strip().replace(\"\\n\", \" \")  # Remove excessive newlines\n",
    "\n",
    "            # Write the extracted data to the CSV file\n",
    "            writer.writerow([title, source, date, body, link])\n",
    "\n",
    "            print(f\"Saved article: {title}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting article data from {link}: {e}\")\n",
    "\n",
    "print(f\"\\nScraping complete! Data saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to check up that the more button is work properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 'More' button clicked 1 times\n",
      "🔄 Total articles loaded: 15\n",
      "✅ 'More' button clicked 2 times\n",
      "🔄 Total articles loaded: 25\n",
      "✅ 'More' button clicked 3 times\n",
      "🔄 Total articles loaded: 35\n",
      "\n",
      "✅ 'More' button test complete!\n"
     ]
    }
   ],
   "source": [
    "click_count = 0\n",
    "max_clicks = 3  # Maximum clicks\n",
    "\n",
    "while click_count < max_clicks:\n",
    "    try:\n",
    "        # Locate the \"More\" button\n",
    "        more_button = driver.find_element(By.XPATH, '//*[@id=\"archive-wrapper\"]/div[5]/div/button')\n",
    "        \n",
    "        # Scroll into view and click\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", more_button)\n",
    "        time.sleep(1)\n",
    "        driver.execute_script(\"arguments[0].click();\", more_button)  # Click using JavaScript\n",
    "        time.sleep(5)  # Wait for new articles to load\n",
    "        \n",
    "        click_count += 1\n",
    "        print(f\" 'More' button clicked {click_count} times\")\n",
    "        \n",
    "        # Check if new articles are loaded\n",
    "        articles = driver.find_elements(By.XPATH, '//*[@id=\"archive-wrapper\"]/div[4]/div[1]/div/div')\n",
    "        print(f\"Total articles loaded: {len(articles)}\")\n",
    "        \n",
    "        if len(articles) == 0:\n",
    "            print(\" No new articles found after clicking. Stopping.\")\n",
    "            break\n",
    "        \n",
    "    except (NoSuchElementException, ElementClickInterceptedException):\n",
    "        print(\"⚠️ No 'More' button found or can't be clicked. Stopping.\")\n",
    "        break  # Stop if the button is missing or can't be clicked\n",
    "\n",
    "print(\"\\n✅ 'More' button test complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fully code to scrape the last 2month data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved article: India's Cornerstone Ventures hits first close of second fund at around $40m - 15 ,01, 2025\n",
      "✅ Saved article: DEG commits to invest $40m in Jungle Ventures's fifth vehicle - 15 ,01, 2025\n",
      "✅ Saved article: Indonesian fintech startup Skor Technologies secures $6.2m funding led by Argor Capital - 14 ,01, 2025\n",
      "✅ Saved article: Indonesian AI startup Bythen secures $5m funding led by Vector Inc, Skystar Capital - 14 ,01, 2025\n",
      "✅ Saved article: India's Boba tea and Korean fusion food brand Boba Bhai bags funding - 13 ,01, 2025\n",
      "✅ Saved article: PE major EQT anchors Cornerstone Robotics's $70m funding - 13 ,01, 2025\n",
      "✅ Saved article: HK's Betatron Venture Group backs construction firm Varadise - 12 ,01, 2025\n",
      "✅ Saved article: India Digest: GrayQuest, BluSmart in funding news - 10 ,01, 2025\n",
      "✅ Saved article: Indian NBFC Infinity Fincorp raises $35m led by Jungle Ventures - 10 ,01, 2025\n",
      "✅ Saved article: Healthcare SaaS startup Innovaccer raises $275m from B Capital, others - 10 ,01, 2025\n",
      "✅ Saved article: Vietnamese edtech firm Kyna English raises funds and other SE Asia deals - 10 ,01, 2025\n",
      "✅ Saved article: PE-VC investments in Indian healthcare hold steady in 2024 - 10 ,01, 2025\n",
      "✅ Saved article: IFC likely to lead AND Global's Series B round with $7m investment - 10 ,01, 2025\n",
      "✅ Saved article: Wealth management platform Endowus raises $17.5m more in latest funding round - 09 ,01, 2025\n",
      "✅ Saved article: Chinese robotics firm Fourier books nearly $109m in Prosperity7-backed Series E round - 08 ,01, 2025\n",
      "✅ Saved article: Indonesian culinary marketplace bukaPO raises funding from Bali Investment Club, elea Foundation - 08 ,01, 2025\n",
      "✅ Saved article: Indonesia’s agritech startup HiFeed bags funding from Wavemaker Impact - 08 ,01, 2025\n",
      "✅ Saved article: Woori Venture Partners invests in SG wireless charging firm Xnergy - 08 ,01, 2025\n",
      "✅ Saved article: Baidu-backed Weimai closes Series D round, eyes IPO in two years - 08 ,01, 2025\n",
      "✅ Saved article: India Digest: Oben Electric, EMO Energy bag funding; Petronas arm eyes $400m - 07 ,01, 2025\n",
      "✅ Saved article: Indonesia’s Soul Parking raises Series A+ funding led by AppWorks, AC Ventures - 06 ,01, 2025\n",
      "✅ Saved article: Japan's Z Venture Capital launches $190m new fund - 06 ,01, 2025\n",
      "✅ Saved article: After 2021 frenzy, we are now operating in grounded environment: Rukam Capital - 06 ,01, 2025\n",
      "✅ Saved article: Chinese national fund fuels aerospace growth with two $100m-plus deals - 02 ,01, 2025\n",
      "✅ Saved article: Qiming-backed robotruck maker DeepWay bags over $102m in Series B - 02 ,01, 2025\n",
      "✅ Saved article: Qiming-backed biotech firm AusperBio raises $73m in Series B round - 02 ,01, 2025\n",
      "✅ Saved article: Chinese EV brand IM Motors raises $192m in fresh Series B round tranche - 02 ,01, 2025\n",
      "✅ Saved article: Silicon Valley VC Accel raises $650m for eighth India fund — same as predecessor - 02 ,01, 2025\n",
      "✅ Saved article: Indian regulator approves stake sale in Prataap Snacks by Peak XV - 31 ,12, 2024\n",
      "✅ Saved article: India Digest: EPACK Prefab, Univest secure funding - 24 ,12, 2024\n",
      "✅ Saved article: Quantum AI startup SandboxAQ raises $300m at $5.6b valuation - 19 ,12, 2024\n",
      "✅ Saved article: India Digest: Bizom, Seekho app, Zingbus raise funds - 19 ,12, 2024\n",
      "✅ Saved article: Hohem closes Series B round and 25 Greater China deals worth around $1.4b - 18 ,12, 2024\n",
      "✅ Saved article: India Digest: HDFC AMC backs Athera Venture Partners; Warmup Ventures launches Fund II - 18 ,12, 2024\n",
      "✅ Saved article: China's EV maker Avatr raises $1.52b in fresh fundraising - 18 ,12, 2024\n",
      "✅ Saved article: AI startup Databricks seals $10b funding with participation from GIC - 17 ,12, 2024\n",
      "✅ Saved article: Alibaba Entrepreneurs Fund's $150m new AI-focused vehicle hits first close - 17 ,12, 2024\n",
      "✅ Saved article: Digest: Endowus partners HPS; Warburg hits first close of continuation fund; KAST raises $10m - 17 ,12, 2024\n",
      "✅ Saved article: Japan's Global Brain to step up SE Asia focus, partners SEEDS Capital - 17 ,12, 2024\n",
      "✅ Saved article: India's Sterlite Power raises $86m from GEF Capital Partners, ENAM Holdings - 16 ,12, 2024\n",
      "✅ Saved article: Bukalapak co-founder Achmad Zaky invests in two edtech startups - 16 ,12, 2024\n",
      "✅ Saved article: VFLO Medical raises Series B round and 53 Greater China deals worth over $1.3b - 15 ,12, 2024\n",
      "✅ Saved article: Databricks nears record $9.5b VC raise from GIC, others - 14 ,12, 2024\n",
      "✅ Saved article: US-based QED Investors leads $25.5m funding round in India's One Card - 14 ,12, 2024\n",
      "✅ Saved article: India Digest: Snapmint, FirstClub, FinX raise funding - 13 ,12, 2024\n",
      "✅ Saved article: Singapore's Eureka Robotics raises $10.5m from B Capital, others - 13 ,12, 2024\n",
      "✅ Saved article: Kenro Capital makes maiden investment in Indian edtech firm K12 Techno - 13 ,12, 2024\n",
      "✅ Saved article: Bosch’s Boyuan Capital targets $207m for second RMB fund - 13 ,12, 2024\n",
      "✅ Saved article: Gobi Partners looks to raise $50m for second Pakistan-focused VC fund - 13 ,12, 2024\n",
      "✅ Saved article: Mubadala, others invest in AI infra provider Crusoe's $600m Series D - 13 ,12, 2024\n",
      "✅ Saved article: Asia Digest: Pak online marketplace LAAM, UAE biotech startup BioSapiens raise funds - 12 ,12, 2024\n",
      "✅ Saved article: SG co-living startup Cove raises $4.5m fresh funding and other SE Asia deals - 12 ,12, 2024\n",
      "✅ Saved article: Bain Capital leads $120m Series C for Angitia Biopharma - 12 ,12, 2024\n",
      "✅ Saved article: India: Robotics startup Haber raises $44m led by Creaegis, BEENEXT, Accel - 11 ,12, 2024\n",
      "✅ Saved article: Deals Digest: Rigel Capital backs workplace design firm; EAAIF bets on Pak aviation fuel - 11 ,12, 2024\n",
      "✅ Saved article: SAIC Motor’s auto logistics unit pockets over $275m from two new investors - 11 ,12, 2024\n",
      "✅ Saved article: Ex-HongShan partner holds first close of maiden healthcare RMB VC fund - 11 ,12, 2024\n",
      "✅ Saved article: CarDekho SEA secures $60m from Navis, Dragon Fund to expand in region - 11 ,12, 2024\n",
      "✅ Saved article: China's GCL Perovskite raises $69m Series C1 round led by Goldstone Investment - 10 ,12, 2024\n",
      "✅ Saved article: China Digest: Kaida, Raintree Scientific Instruments, Vanteque raise funds - 10 ,12, 2024\n",
      "✅ Saved article: New funds stand out in 2024 even as overall VC fundraising dips in India - 10 ,12, 2024\n",
      "✅ Saved article: Google-backed Indian spacetech startup Pixxel raises $24m in Series B extension - 09 ,12, 2024\n",
      "✅ Saved article: SG energy solution provider BECIS secures $53m from FMO, others - 09 ,12, 2024\n",
      "✅ Saved article: Indian furniture retailer WoodenStreet raises $43m in Series C round from Premji Invest - 09 ,12, 2024\n",
      "✅ Saved article: Singapore SaaS firm Omni HR raises $7.4m led by Picus Capital - 09 ,12, 2024\n",
      "✅ Saved article: Taiwanese travel startup KKday pockets $70m for M&As, AI investments - 05 ,12, 2024\n",
      "✅ Saved article: National fund-of-funds Jelawang Capital spots big promise for Malaysian VCs - 05 ,12, 2024\n",
      "✅ Saved article: India Digest: Solar startup Glow raises $30m; Peak XV backs US-based AI startup - 04 ,12, 2024\n",
      "✅ Saved article: Fintech startup KPay Group secures $55m Series A funding led by Apis Partners - 03 ,12, 2024\n",
      "✅ Saved article: After $2b payday from Swiggy, Prosus plans more listings from Indian portfolio - 02 ,12, 2024\n",
      "✅ Saved article: India's private markets poised for a big rebound in 2025: 3one4 Capital - 02 ,12, 2024\n",
      "✅ Saved article: Lanchi Ventures leads $42m Series A round for Chinese biotech startup Allink - 28 ,11, 2024\n",
      "✅ Saved article: India: Early-stage investor Stellaris Venture Partners closes third fund at $300m - 28 ,11, 2024\n",
      "✅ Saved article: Former Peak XV exec's fund taps VC secondaries in India, SE Asia - 28 ,11, 2024\n",
      "✅ Saved article: Japanese digital bank Habitto raises $11.7m in Series A funding - 27 ,11, 2024\n",
      "✅ Saved article: SG digital receipts provider Pi-xcels raises $2.7m for global expansion - 27 ,11, 2024\n",
      "✅ Saved article: Temasek-backed OneCard raising $28.5m from investors to expand ops - 26 ,11, 2024\n",
      "✅ Saved article: Worg Pharma bags funding and 26 Greater China deals worth almost $307m - 26 ,11, 2024\n",
      "✅ Saved article: Gobi Partners, Cross Capital join hands to boost Japanese investment in SE Asia - 26 ,11, 2024\n",
      "✅ Saved article: Vynn Capital leads $8.75m seed funding for MediSun Energy - 25 ,11, 2024\n",
      "✅ Saved article: Sequoia Capital marks up value of 2020 US venture fund by 24.6% - 25 ,11, 2024\n",
      "✅ Saved article: India: IPO-bound quick commerce company Zepto raises another $350m funding - 22 ,11, 2024\n",
      "✅ Saved article: SG logistics startup Locad raises $9m and other SE Asia deals - 22 ,11, 2024\n",
      "⏹️ Stopping: Found an article older than 2 months (21 ,11, 2024)\n",
      "\n",
      " Scraping complete! Data saved to full_scraped_articles.csv\n"
     ]
    }
   ],
   "source": [
    "# Initialize WebDriver\n",
    "driver = webdriver.Chrome()  # Change this if using a different browser\n",
    "driver.get(\"https://www.dealstreetasia.com/section/venture-capital\")\n",
    "time.sleep(3)  # Wait for page to load\n",
    "\n",
    "# Define the exact date limit (2 months ago)\n",
    "two_months_ago = datetime.now() - timedelta(days=60)\n",
    "\n",
    "# Create CSV file for writing\n",
    "csv_filename = \"full_scraped_articles.csv\"\n",
    "with open(csv_filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Source\", \"Date\", \"Article Content\", \"URL\"])  # CSV Header\n",
    "\n",
    "    # Function to parse and reformat date\n",
    "    def parse_and_format_date(date_str):\n",
    "        try:\n",
    "            parsed_date = datetime.strptime(date_str, \"%d %B, %Y\")  # Convert '14 January, 2025'\n",
    "            return parsed_date.strftime(\"%d ,%m, %Y\")  # Format to '14 ,01, 2025'\n",
    "        except ValueError:\n",
    "            return None  # Handle unexpected formats\n",
    "\n",
    "    last_article_old = False  # Stop when an article older than 2 months is found\n",
    "    last_scraped_index = 0  # Keep track of last scraped article index\n",
    "\n",
    "    while not last_article_old:\n",
    "        # Step 1: Extract all current article links\n",
    "        articles = driver.find_elements(By.XPATH, '//*[@id=\"archive-wrapper\"]/div[4]/div[1]/div/div')\n",
    "        article_links = [article.find_element(By.XPATH, './div[1]/a').get_attribute('href') for article in articles]\n",
    "\n",
    "        # Start from the last scraped index (continue from where we left off)\n",
    "        for i in range(last_scraped_index, len(article_links)):\n",
    "            link = article_links[i]\n",
    "            driver.get(link)\n",
    "            time.sleep(2)  # Wait for article page to load\n",
    "\n",
    "            try:\n",
    "                # Extract article details\n",
    "                title = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/h1').text.strip()\n",
    "                source = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[1]/div/div[1]/span/a').text.strip()\n",
    "                date_text = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[1]/div/div[1]/p').text.strip()\n",
    "                body = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[2]/div[1]/article').text.strip().replace(\"\\n\", \" \")\n",
    "\n",
    "                # Convert date and compare with the 2-month limit\n",
    "                formatted_date = parse_and_format_date(date_text)\n",
    "                article_date = datetime.strptime(formatted_date, \"%d ,%m, %Y\") if formatted_date else None\n",
    "\n",
    "                if article_date and article_date < two_months_ago:\n",
    "                    print(f\"⏹️ Stopping: Found an article older than 2 months ({formatted_date})\")\n",
    "                    last_article_old = True\n",
    "                    break  # Stop processing further\n",
    "\n",
    "                # Save to CSV\n",
    "                writer.writerow([title, source, formatted_date, body, link])\n",
    "                print(f\"✅ Saved article: {title} - {formatted_date}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\" Error extracting article data from {link}: {e}\")\n",
    "\n",
    "            # Update last scraped index\n",
    "            last_scraped_index = i + 1\n",
    "\n",
    "            # Go back to the main page to scrape the next article\n",
    "            driver.back()\n",
    "            time.sleep(2)  # Wait for the main page to reload\n",
    "\n",
    "        if last_article_old:\n",
    "            break  # Stop clicking \"More\" if we found an old article\n",
    "\n",
    "        # Step 2: Click the \"More\" button to load more articles\n",
    "        try:\n",
    "            more_button = driver.find_element(By.XPATH, '//*[@id=\"archive-wrapper\"]/div[5]/div/button')\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", more_button)\n",
    "            time.sleep(1)\n",
    "            driver.execute_script(\"arguments[0].click();\", more_button)\n",
    "            time.sleep(5)  # Wait for new articles to load\n",
    "\n",
    "            # Update last_scraped_index to continue from where we left off\n",
    "            last_scraped_index = len(article_links)\n",
    "\n",
    "        except (NoSuchElementException, ElementClickInterceptedException):\n",
    "            print(\" No 'More' button found or can't be clicked. Stopping.\")\n",
    "            break  # Stop if the button is missing or can't be clicked\n",
    "\n",
    "print(f\"\\n Scraping complete! Data saved to {csv_filename}\")\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
