{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*[@id=\"archive-wrapper\"]/div[4]/div[1]/div/div[1]\n",
    "# //*[@id=\"archive-wrapper\"]/div[4]/div[1]/div/div[1]/div[1]/a ...link adress\n",
    "# //*[@id=\"disable-copy\"]/h1...title\n",
    "# //*[@id=\"disable-copy\"]/div[2]/div[1]/div/div[1]/span/a ...source\n",
    "# //*[@id=\"disable-copy\"]/div[2]/div[1]/div/div[1]/p....date\n",
    "# //*[@id=\"disable-copy\"]/div[2]/div[2]/div[1]/article...body \n",
    "# //*[@id=\"archive-wrapper\"]/div[4]/div[1]/div/div[2]\n",
    "# //*[@id=\"disable-copy\"]/h1 ...title\n",
    "# //*[@id=\"disable-copy\"]/div[2]/div[1]/div/div[1]/p ...date\n",
    "# //*[@id=\"disable-copy\"]/div[2]/div[2]/div[1]/article...body\n",
    "# //*[@id=\"disable-copy\"]/div[2]/div[1]/div/div[1]/span/a\n",
    "# //*[@id=\"archive-wrapper\"]/div[4]/div[1]/div/div[3]\n",
    "# ...\n",
    "# //*[@id=\"archive-wrapper\"]/div[4]/div[1]/div/div[8]\n",
    "\n",
    "# //*[@id=\"archive-wrapper\"]/div[5]/div/button\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Selenium WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run in headless mode for efficiency\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Open the target website\n",
    "url = \"https://www.dealstreetasia.com/section/private-equity\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start to check that the scripts are really get the required information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article: Indian PE giant Kedaara invests $350m in AI solution provider Impetus\n",
      "Saved article: Gaw Capital buys 45% stake in Agility Asset Advisers to deepen presence in Japan\n",
      "Saved article: Indian NBFC Saarathi Finance in talks with PE firms to raise capital\n",
      "Saved article: GPs' soft skills equally important amid Asia's shifting landscape, says veteran LP\n",
      "Saved article: Oriza's semiconductor investment platform achieves first close of debut M&A fund\n",
      "\n",
      "Scraping complete! Data saved to scraped_articles.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "# Set up Selenium WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run in headless mode for efficiency\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Open the target website\n",
    "url = \"https://www.dealstreetasia.com/section/private-equity\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the page to load\n",
    "time.sleep(3)  # Adjust based on page load time\n",
    "\n",
    "# Extract article links\n",
    "articles = driver.find_elements(By.XPATH, '//*[@id=\"archive-wrapper\"]/div[4]/div[1]/div/div')\n",
    "article_links = [article.find_element(By.XPATH, './div[1]/a').get_attribute('href') for article in articles]\n",
    "\n",
    "# Create and open a CSV file for writing\n",
    "csv_filename = \"scraped_articles.csv\"\n",
    "with open(csv_filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Source\", \"Date\", \"Article Content\", \"URL\"])  # Added URL column\n",
    "\n",
    "    # Loop through each article link and extract details\n",
    "    for link in article_links:\n",
    "        driver.get(link)\n",
    "        time.sleep(2)  # Ensure the page loads before extracting data\n",
    "\n",
    "        try:\n",
    "            # Extract article details\n",
    "            title = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/h1').text.strip()\n",
    "            source = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[1]/div/div[1]/span/a').text.strip()\n",
    "            date = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[1]/div/div[1]/p').text.strip()\n",
    "            body = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[2]/div[1]/article').text.strip().replace(\"\\n\", \" \")  # Remove excessive newlines\n",
    "\n",
    "            # Write the extracted data to the CSV file\n",
    "            writer.writerow([title, source, date, body, link])\n",
    "\n",
    "            print(f\"Saved article: {title}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting article data from {link}: {e}\")\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "print(f\"\\nScraping complete! Data saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'More' button clicked 1 times\n",
      "'More' button clicked 2 times\n",
      "'More' button clicked 3 times\n",
      "'More' button clicked 4 times\n",
      "'More' button clicked 5 times\n",
      "Saved article: Indian PE giant Kedaara invests $350m in AI solution provider Impetus\n",
      "Saved article: Gaw Capital buys 45% stake in Agility Asset Advisers to deepen presence in Japan\n",
      "Saved article: Indian NBFC Saarathi Finance in talks with PE firms to raise capital\n",
      "Saved article: GPs' soft skills equally important amid Asia's shifting landscape, says veteran LP\n",
      "Saved article: Oriza's semiconductor investment platform achieves first close of debut M&A fund\n",
      "Saved article: TPG said to have closed investment in Asian flower business Hasfarm Holdings\n",
      "Saved article: PAG acquires majority stake in Indian packaging firm Pravesha Industries\n",
      "Saved article: Vietnam-based PE firm ABB closes second fund at $70m\n",
      "Saved article: Bain Capital ups bid for Australia's Insignia to $1.8b, matching CC Capital\n",
      "Saved article: India’s healthcare boom lures big chunk of $14b private equity money\n",
      "Saved article: Kotak fund injects $109m into Indian IPO-hopeful Neuberg Diagnostics\n",
      "Saved article: Apollo weighs $9.5b investment in Seven & i management buyout: report\n",
      "Saved article: PE-VC investments in Indian healthcare hold steady in 2024\n",
      "Saved article: Vietnamese startup Gene Solutions ropes in SG's August Global as backer\n",
      "Saved article: Blue Earth Capital sees secondaries driving impact investments\n",
      "Saved article: Consortium offering to take over Malaysia Airports secures 84.1% stake\n",
      "Saved article: India's Botanic Healthcare bags $29m led by PE firm Skateboat Capital\n",
      "Saved article: Despite strong PE interest, Indian healthcare remains fragmented: Quadria\n",
      "Saved article: China's $47b third semiconductor 'Big Fund' kickstarts investments\n",
      "Saved article: Temasek said to have emerged as frontrunner to pick stake in India's Haldiram: Report\n",
      "Saved article: KKR said to be weighing sale of Japan's Seiyu supermarket\n",
      "Saved article: Bain Capital keen to look beyond healthcare sector in Indonesia\n",
      "Saved article: SG data centre provider Digital Edge secures $1.6b in fresh funding\n",
      "Saved article: Australia's Insignia Financial gets $1.8b takeover bid from CC Capital Partners\n",
      "Saved article: Norway sovereign wealth fund buys 45% stake in US real estate portfolio for $1b\n",
      "Saved article: India-focused PE-VC funds raise $6.8b in 2024, fail to match 2023 levels\n",
      "Saved article: Creador buys majority stake in Indonesian B2B hospitality firm MG Group\n",
      "Saved article: Mubadala acquires majority stake in UAE pharma firms\n",
      "Saved article: EQT, Temasek to sell O2 Power to JSW Neo Energy for $1.5b\n",
      "Saved article: KKR and Bain bid more than $5b each for Seven & i's non-core assets\n",
      "Saved article: Top PE deals that defined the Indian investment landscape in 2024\n",
      "Saved article: Korea's SK Inc to sell $1.86b stake in gas unit to PE firm Hahn & Co\n",
      "Saved article: Prosus to buy Latin America-focused online travel agency Despegar.com for $1.7b\n",
      "Saved article: Tamarind Health, Temasek-backed 65 Equity Partners offer to buy SGX-listed TalkMed\n",
      "Saved article: Excelsior Capital Vietnam Partners hits first close of second fund\n",
      "Saved article: Private equity firms pledge to be China-free as US tightens rules\n",
      "Saved article: Top secondaries deals in Asia that marked PE landscape in 2024\n",
      "Saved article: Creador secures $40m from FinDev Canada for sixth fund\n",
      "Saved article: After Delhivery, Multiples backs another Indian logistics startup INSTANT-XP\n",
      "Saved article: After Temasek, KKR backs Indian cloud kitchen startup Rebel Foods\n",
      "Saved article: GLP Capital Partners bags $383m for latest China income fund\n",
      "Saved article: PH Digest: Navegar exiting Royale Cold Storage; Pinnacle selling minority stake\n",
      "Saved article: GIC invests another $150m in India's TPG-backed Asia Healthcare\n",
      "Saved article: Bain's $1.7b offer rebuffed by Australia's Insignia on valuation concerns\n",
      "Saved article: Fuji Soft sticks with KKR, rejects Bain's raised buyout offer\n",
      "Saved article: Nuveen secures $100m private capital mandate from South Korean pension manager\n",
      "Saved article: DEG commits $15m to Amicus Capital's second India fund\n",
      "Saved article: Japanese cosmetics group Kose buys Lakeshore-backed skincare brand Panpuri\n",
      "Saved article: Greater China Digest: I Squared mulls offer for HKBN; Beijing Tongyizhong to buy X-Fiper\n",
      "Saved article: Five trends & strategies that will define Asia's PE landscape in 2025\n",
      "Saved article: Bain Capital offers to buy Australia's Insignia Financial for $1.7b\n",
      "Saved article: APAC may beat global markets in PE returns recovery: Preqin\n",
      "Saved article: Bain, KKR, JIP advance to next round of bidding for Seven & i's non-core ops\n",
      "Saved article: Orsted sells 50% stake in Greater Changhua 4 wind farm for $1.64bn\n",
      "Saved article: Realistic expectations, ageing sponsor portfolios to propel SE Asia buyouts\n",
      "\n",
      "Scraping complete! Data saved to more scraped_articles.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Set up Selenium WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run in headless mode for efficiency\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Open the target website\n",
    "url = \"https://www.dealstreetasia.com/section/private-equity\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the page to load\n",
    "time.sleep(3)  # Adjust based on page load time\n",
    "\n",
    "# Click the \"More\" button up to 5 times to load more articles\n",
    "max_clicks = 5\n",
    "click_count = 0\n",
    "\n",
    "while click_count < max_clicks:\n",
    "    try:\n",
    "        more_button = driver.find_element(By.XPATH, '//*[@id=\"archive-wrapper\"]/div[5]/div/button')\n",
    "        driver.execute_script(\"arguments[0].click();\", more_button)  # Click using JavaScript\n",
    "        time.sleep(3)  # Wait for new articles to load\n",
    "        click_count += 1\n",
    "        print(f\"'More' button clicked {click_count} times\")\n",
    "    except (NoSuchElementException, ElementClickInterceptedException):\n",
    "        print(\"No more articles to load or button is unavailable.\")\n",
    "        break  # Stop clicking if the button is missing or can't be clicked\n",
    "\n",
    "# Extract article links after loading more content\n",
    "articles = driver.find_elements(By.XPATH, '//*[@id=\"archive-wrapper\"]/div[4]/div[1]/div/div')\n",
    "article_links = [article.find_element(By.XPATH, './div[1]/a').get_attribute('href') for article in articles]\n",
    "\n",
    "# Create and open a CSV file for writing\n",
    "csv_filename = \"more scraped_articles.csv\"\n",
    "with open(csv_filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Source\", \"Date\", \"Article Content\", \"URL\"])  # Added URL column\n",
    "\n",
    "    # Loop through each article link and extract details\n",
    "    for link in article_links:\n",
    "        driver.get(link)\n",
    "        time.sleep(2)  # Ensure the page loads before extracting data\n",
    "\n",
    "        try:\n",
    "            # Extract article details\n",
    "            title = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/h1').text.strip()\n",
    "            source = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[1]/div/div[1]/span/a').text.strip()\n",
    "            date = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[1]/div/div[1]/p').text.strip()\n",
    "            body = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[2]/div[1]/article').text.strip().replace(\"\\n\", \" \")  # Remove excessive newlines\n",
    "\n",
    "            # Write the extracted data to the CSV file\n",
    "            writer.writerow([title, source, date, body, link])\n",
    "\n",
    "            print(f\"Saved article: {title}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting article data from {link}: {e}\")\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "print(f\"\\nScraping complete! Data saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: Indian PE giant Kedaara invests $350m in AI solution provider Impetus (2025-01-16)\n",
      "Saved: Gaw Capital buys 45% stake in Agility Asset Advisers to deepen presence in Japan (2025-01-16)\n",
      "Saved: Indian NBFC Saarathi Finance in talks with PE firms to raise capital (2025-01-16)\n",
      "Saved: GPs' soft skills equally important amid Asia's shifting landscape, says veteran LP (2025-01-15)\n",
      "Saved: Oriza's semiconductor investment platform achieves first close of debut M&A fund (2025-01-15)\n",
      "No more 'More' button found. Scraping complete.\n",
      "\n",
      "Scraping complete! Data saved to filtered_articles_last_2_months.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Set up Selenium WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run in headless mode for efficiency\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Open the target website\n",
    "url = \"https://www.dealstreetasia.com/section/private-equity\"\n",
    "driver.get(url)\n",
    "time.sleep(3)  \n",
    "\n",
    "# Set date threshold (2 months ago)\n",
    "two_months_ago = datetime.now() - timedelta(days=2 * 30)  # Approximate 2 months\n",
    "\n",
    "# Open CSV file for writing\n",
    "csv_filename = \"filtered_articles_last_2_months.csv\"\n",
    "with open(csv_filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Source\", \"Date\", \"Article Content\", \"URL\"])  # CSV Headers\n",
    "\n",
    "    stop_scraping = False  # Flag to stop when old articles appear\n",
    "\n",
    "    while not stop_scraping:\n",
    "        # Extract article links from the current page\n",
    "        articles = driver.find_elements(By.XPATH, '//*[@id=\"archive-wrapper\"]/div[4]/div[1]/div/div')\n",
    "        article_links = [article.find_element(By.XPATH, './div[1]/a').get_attribute('href') for article in articles]\n",
    "\n",
    "        # Loop through each article link and extract details\n",
    "        for link in article_links:\n",
    "            driver.get(link)\n",
    "            time.sleep(1)  \n",
    "\n",
    "            try:\n",
    "                title = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/h1').text.strip()\n",
    "                source = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[1]/div/div[1]/span/a').text.strip()\n",
    "                date_text = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[1]/div/div[1]/p').text.strip()\n",
    "                body = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[2]/div[1]/article').text.strip().replace(\"\\n\", \" \")  \n",
    "\n",
    "                # Convert date format\n",
    "                try:\n",
    "                    article_date = datetime.strptime(date_text, \"%d %B, %Y\")\n",
    "                except ValueError:\n",
    "                    print(f\"Skipping article with invalid date format: {date_text}\")\n",
    "                    continue  \n",
    "\n",
    "                # Stop if article is older than 2 months\n",
    "                if article_date < two_months_ago:\n",
    "                    print(f\"Stopping: Found old article {title} ({article_date.strftime('%Y-%m-%d')})\")\n",
    "                    stop_scraping = True\n",
    "                    break  \n",
    "\n",
    "                # Save data to CSV\n",
    "                writer.writerow([title, source, article_date.strftime(\"%Y-%m-%d\"), body, link])\n",
    "                print(f\"Saved: {title} ({article_date.strftime('%Y-%m-%d')})\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting data from {link}: {e}\")\n",
    "\n",
    "        # If we already found an old article, stop scraping\n",
    "        if stop_scraping:\n",
    "            break  \n",
    "\n",
    "        # Click the \"More\" button to load additional articles\n",
    "        try:\n",
    "            more_button = driver.find_element(By.XPATH, '//*[@id=\"archive-wrapper\"]/div[5]/div/button')\n",
    "            driver.execute_script(\"arguments[0].click();\", more_button)  \n",
    "            time.sleep(3)  \n",
    "            print(\"Clicked 'More' button to load additional articles.\")\n",
    "        except (NoSuchElementException, ElementClickInterceptedException):\n",
    "            print(\"No more 'More' button found. Scraping complete.\")\n",
    "            break  \n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "print(f\"\\nScraping complete! Data saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException, TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Scraping articles from current page (Click count: 0)...\n",
      "\n",
      "✅ Saved: Indian PE giant Kedaara invests $350m in AI solution provider Impetus (2025-01-16)\n",
      "✅ Saved: Gaw Capital buys 45% stake in Agility Asset Advisers to deepen presence in Japan (2025-01-16)\n",
      "✅ Saved: Indian NBFC Saarathi Finance in talks with PE firms to raise capital (2025-01-16)\n",
      "✅ Saved: GPs' soft skills equally important amid Asia's shifting landscape, says veteran LP (2025-01-15)\n",
      "✅ Saved: Oriza's semiconductor investment platform achieves first close of debut M&A fund (2025-01-15)\n",
      "\n",
      "⚠️ No more 'More' button found. Stopping scraping.\n",
      "\n",
      "\n",
      "✅ Scraping complete! Data saved to 2_months.csv\n"
     ]
    }
   ],
   "source": [
    "# =================== Helper Functions ===================\n",
    "\n",
    "def parse_date(date_text):\n",
    "    \"\"\"Convert date string to datetime object. Format: '16 January, 2025' -> 'YYYY-MM-DD'\"\"\"\n",
    "    try:\n",
    "        parsed_date = datetime.strptime(date_text, \"%d %B, %Y\")\n",
    "        return parsed_date.strftime(\"%Y-%m-%d\")  # Convert to standard format\n",
    "    except ValueError:\n",
    "        return None  # Return None if the format is incorrect\n",
    "\n",
    "def is_within_last_2_months(article_date):\n",
    "    \"\"\"Check if the article date is within the last 2 months\"\"\"\n",
    "    if article_date is None:\n",
    "        return False\n",
    "    today = datetime.today()\n",
    "    two_months_ago = today.replace(month=today.month - 2 if today.month > 2 else 12 + (today.month - 2), year=today.year if today.month > 2 else today.year - 1)\n",
    "    return datetime.strptime(article_date, \"%Y-%m-%d\") >= two_months_ago\n",
    "\n",
    "# =================== Selenium Setup ===================\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run in headless mode for efficiency\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Open the website\n",
    "url = \"https://www.dealstreetasia.com/section/private-equity\"\n",
    "driver.get(url)\n",
    "time.sleep(3)  # Allow page to load\n",
    "\n",
    "# Create CSV file and write header if not exists\n",
    "csv_filename = \"articles.csv\"\n",
    "scraped_urls = set()  # Track scraped URLs\n",
    "\n",
    "try:\n",
    "    with open(csv_filename, mode=\"r\", encoding=\"utf-8\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Skip header\n",
    "        for row in reader:\n",
    "            scraped_urls.add(row[4])  # Add existing URLs\n",
    "except FileNotFoundError:\n",
    "    with open(csv_filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Title\", \"Source\", \"Date\", \"Article\", \"URL\"])  # CSV Headers\n",
    "\n",
    "# =================== Scraping Logic ===================\n",
    "\n",
    "click_count = 0\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Wait for articles to load\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"archive-wrapper\"]/div[4]/div[1]/div/div')))\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error waiting for articles: {e}\")\n",
    "        break\n",
    "\n",
    "    # Get all articles on the current loaded page\n",
    "    articles = driver.find_elements(By.XPATH, '//*[@id=\"archive-wrapper\"]/div[4]/div[1]/div/div')\n",
    "\n",
    "    for index in range(len(articles)):  # Use index instead of directly iterating\n",
    "        try:\n",
    "            # Re-locate articles on each iteration to avoid stale references\n",
    "            articles = driver.find_elements(By.XPATH, '//*[@id=\"archive-wrapper\"]/div[4]/div[1]/div/div')\n",
    "            article = articles[index]\n",
    "\n",
    "            # Extract article link\n",
    "            link_element = article.find_element(By.XPATH, './/div[1]/a')\n",
    "            article_url = link_element.get_attribute(\"href\")\n",
    "\n",
    "            # ✅ **Skip if article is already scraped**\n",
    "            if article_url in scraped_urls:\n",
    "                print(f\"⚠️ Skipping already scraped article: {article_url}\")\n",
    "                continue\n",
    "\n",
    "            driver.execute_script(\"arguments[0].click();\", link_element)  # Click article link\n",
    "            time.sleep(1)  # Wait for article page to load\n",
    "\n",
    "            # Extract information\n",
    "            title = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"disable-copy\"]/h1'))).text\n",
    "            source = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[1]/div/div[1]/span/a').text\n",
    "            date_text = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[1]/div/div[1]/p').text\n",
    "            article_content = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[2]/div[1]/article').text\n",
    "\n",
    "            # Convert and check date\n",
    "            article_date = parse_date(date_text)\n",
    "            if not is_within_last_2_months(article_date):\n",
    "                print(f\"\\n✅ Scraping ended: No more articles within the last 2 months.\")\n",
    "                driver.quit()\n",
    "                exit()\n",
    "\n",
    "            # Save article data\n",
    "            with open(csv_filename, mode=\"a\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([title, source, article_date, article_content, article_url])\n",
    "                scraped_urls.add(article_url)  # Add to scraped URLs\n",
    "\n",
    "            print(f\"✅ Scraped: {title}\")\n",
    "\n",
    "            driver.back()  # Go back to the main article page\n",
    "            time.sleep(2)  # Wait before continuing\n",
    "\n",
    "        except (NoSuchElementException, StaleElementReferenceException) as e:\n",
    "            print(f\"⚠️ Skipping article due to error: {e}\")\n",
    "            continue  # Skip and continue to the next article\n",
    "\n",
    "    # Try clicking the \"More\" button to load additional articles\n",
    "    try:\n",
    "        more_button = driver.find_element(By.XPATH, '//*[@id=\"archive-wrapper\"]/div[5]/div/button')\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", more_button)\n",
    "        time.sleep(4)\n",
    "        driver.execute_script(\"arguments[0].click();\", more_button)  # Click using JavaScript\n",
    "        time.sleep(5)  # Wait for new articles to load\n",
    "        click_count += 1\n",
    "        print(f\"🔄 'More' button clicked {click_count} times\")\n",
    "\n",
    "    except (NoSuchElementException, ElementClickInterceptedException):\n",
    "        print(\"⚠️ No 'More' button found or can't be clicked. Ending scrape.\")\n",
    "        break  # Stop clicking if the button is missing\n",
    "\n",
    "# Close browser\n",
    "driver.quit()\n",
    "print(\"\\n✅ Scraping complete! Data saved to 'articles.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.chrome.options.Options at 0x252c9e1c4a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up Selenium WebDriver\n",
    "#options = \n",
    "webdriver.ChromeOptions()\n",
    "#options.add_argument(\"--headless\")  # Run headless for efficiency\n",
    "#driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome() \n",
    "website=\"https://www.dealstreetasia.com/section/private-equity\"  \n",
    "driver.get(website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 'More' button clicked 1 times\n",
      "🔄 Total articles loaded: 15\n",
      "✅ 'More' button clicked 2 times\n",
      "🔄 Total articles loaded: 25\n",
      "✅ 'More' button clicked 3 times\n",
      "🔄 Total articles loaded: 35\n",
      "✅ 'More' button clicked 4 times\n",
      "🔄 Total articles loaded: 45\n",
      "✅ 'More' button clicked 5 times\n",
      "🔄 Total articles loaded: 55\n",
      "\n",
      "✅ 'More' button test complete!\n"
     ]
    }
   ],
   "source": [
    "click_count = 0\n",
    "max_clicks = 5  # Maximum clicks\n",
    "\n",
    "while click_count < max_clicks:\n",
    "    try:\n",
    "        # Locate the \"More\" button\n",
    "        more_button = driver.find_element(By.XPATH, '//*[@id=\"archive-wrapper\"]/div[5]/div/button')\n",
    "        \n",
    "        # Scroll into view and click\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", more_button)\n",
    "        time.sleep(1)\n",
    "        driver.execute_script(\"arguments[0].click();\", more_button)  # Click using JavaScript\n",
    "        time.sleep(5)  # Wait for new articles to load\n",
    "        \n",
    "        click_count += 1\n",
    "        print(f\"✅ 'More' button clicked {click_count} times\")\n",
    "        \n",
    "        # Check if new articles are loaded\n",
    "        articles = driver.find_elements(By.XPATH, '//*[@id=\"archive-wrapper\"]/div[4]/div[1]/div/div')\n",
    "        print(f\"🔄 Total articles loaded: {len(articles)}\")\n",
    "        \n",
    "        if len(articles) == 0:\n",
    "            print(\"⚠️ No new articles found after clicking. Stopping.\")\n",
    "            break\n",
    "        \n",
    "    except (NoSuchElementException, ElementClickInterceptedException):\n",
    "        print(\"⚠️ No 'More' button found or can't be clicked. Stopping.\")\n",
    "        break  # Stop if the button is missing or can't be clicked\n",
    "\n",
    "print(\"\\n✅ 'More' button test complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException, StaleElementReferenceException\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scraped: Indian PE giant Kedaara invests $350m in AI solution provider Impetus\n",
      "✅ Scraped: Gaw Capital buys 45% stake in Agility Asset Advisers to deepen presence in Japan\n",
      "✅ Scraped: Indian NBFC Saarathi Finance in talks with PE firms to raise capital\n",
      "✅ Scraped: GPs' soft skills equally important amid Asia's shifting landscape, says veteran LP\n",
      "✅ Scraped: Oriza's semiconductor investment platform achieves first close of debut M&A fund\n",
      "🔄 'More' button clicked 1 times\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kedaara-impetus-426489/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/gaw-capital-agility-asset-advisers-426453/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/saarathi-finance-funding-426402/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/hkvca-asia-pe-forum-2025-426401/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/oriza-hua-debut-ma-fund-426223/\n",
      "✅ Scraped: TPG said to have closed investment in Asian flower business Hasfarm Holdings\n",
      "✅ Scraped: PAG acquires majority stake in Indian packaging firm Pravesha Industries\n",
      "✅ Scraped: Vietnam-based PE firm ABB closes second fund at $70m\n",
      "✅ Scraped: Bain Capital ups bid for Australia's Insignia to $1.8b, matching CC Capital\n",
      "✅ Scraped: India’s healthcare boom lures big chunk of $14b private equity money\n",
      "✅ Scraped: Kotak fund injects $109m into Indian IPO-hopeful Neuberg Diagnostics\n",
      "✅ Scraped: Apollo weighs $9.5b investment in Seven & i management buyout: report\n",
      "✅ Scraped: PE-VC investments in Indian healthcare hold steady in 2024\n",
      "✅ Scraped: Vietnamese startup Gene Solutions ropes in SG's August Global as backer\n",
      "✅ Scraped: Blue Earth Capital sees secondaries driving impact investments\n",
      "🔄 'More' button clicked 2 times\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kedaara-impetus-426489/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/gaw-capital-agility-asset-advisers-426453/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/saarathi-finance-funding-426402/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/hkvca-asia-pe-forum-2025-426401/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/oriza-hua-debut-ma-fund-426223/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/tpg-hasfarm-holdings-425991/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/pag-pravesha-industries-426162/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/abb-second-pe-fund-426068/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/bain-capital-insignia-cc-capital-426023/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/india-healthcare-private-equity-425836/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kotak-fund-neuberg-diagnostics-425841/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/apollo-seven-i-buyout-425843/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/pe-vc-healthcare-investments-india-425705/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/gene-solutions-august-global-425694/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/blue-earth-secondaries-private-credit-425642/\n",
      "✅ Scraped: Consortium offering to take over Malaysia Airports secures 84.1% stake\n",
      "✅ Scraped: India's Botanic Healthcare bags $29m led by PE firm Skateboat Capital\n",
      "✅ Scraped: Despite strong PE interest, Indian healthcare remains fragmented: Quadria\n",
      "✅ Scraped: China's $47b third semiconductor 'Big Fund' kickstarts investments\n",
      "✅ Scraped: Temasek said to have emerged as frontrunner to pick stake in India's Haldiram: Report\n",
      "✅ Scraped: KKR said to be weighing sale of Japan's Seiyu supermarket\n",
      "✅ Scraped: Bain Capital keen to look beyond healthcare sector in Indonesia\n",
      "✅ Scraped: SG data centre provider Digital Edge secures $1.6b in fresh funding\n",
      "✅ Scraped: Australia's Insignia Financial gets $1.8b takeover bid from CC Capital Partners\n",
      "✅ Scraped: Norway sovereign wealth fund buys 45% stake in US real estate portfolio for $1b\n",
      "🔄 'More' button clicked 3 times\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kedaara-impetus-426489/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/gaw-capital-agility-asset-advisers-426453/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/saarathi-finance-funding-426402/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/hkvca-asia-pe-forum-2025-426401/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/oriza-hua-debut-ma-fund-426223/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/tpg-hasfarm-holdings-425991/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/pag-pravesha-industries-426162/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/abb-second-pe-fund-426068/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/bain-capital-insignia-cc-capital-426023/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/india-healthcare-private-equity-425836/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kotak-fund-neuberg-diagnostics-425841/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/apollo-seven-i-buyout-425843/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/pe-vc-healthcare-investments-india-425705/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/gene-solutions-august-global-425694/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/blue-earth-secondaries-private-credit-425642/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/consortium-malaysia-airports-425648/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/botanic-healthcare-bags-funding-425629/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/quadria-capital-interview-2-425476/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/chinas-47b-third-semiconductor-big-fund-kickstarts-investments-425517/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/temasek-haldiram-425396/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kkr-said-to-be-weighing-sale-of-japans-seiyu-supermarket-425386/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/bain-capital-indonesia-424409/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/digital-edge-fresh-funding-425255/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/australias-insignia-financial-gets-1-8b-takeover-bid-from-cc-capital-partners-425233/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/norway-sovereign-wealth-fund-buys-45-stake-in-us-real-estate-portfolio-for-1b-425137/\n",
      "✅ Scraped: India-focused PE-VC funds raise $6.8b in 2024, fail to match 2023 levels\n",
      "✅ Scraped: Creador buys majority stake in Indonesian B2B hospitality firm MG Group\n",
      "✅ Scraped: Mubadala acquires majority stake in UAE pharma firms\n",
      "✅ Scraped: EQT, Temasek to sell O2 Power to JSW Neo Energy for $1.5b\n",
      "✅ Scraped: KKR and Bain bid more than $5b each for Seven & i's non-core assets\n",
      "✅ Scraped: Top PE deals that defined the Indian investment landscape in 2024\n",
      "✅ Scraped: Korea's SK Inc to sell $1.86b stake in gas unit to PE firm Hahn & Co\n",
      "✅ Scraped: Prosus to buy Latin America-focused online travel agency Despegar.com for $1.7b\n",
      "✅ Scraped: Tamarind Health, Temasek-backed 65 Equity Partners offer to buy SGX-listed TalkMed\n",
      "✅ Scraped: Excelsior Capital Vietnam Partners hits first close of second fund\n",
      "🔄 'More' button clicked 4 times\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kedaara-impetus-426489/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/gaw-capital-agility-asset-advisers-426453/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/saarathi-finance-funding-426402/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/hkvca-asia-pe-forum-2025-426401/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/oriza-hua-debut-ma-fund-426223/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/tpg-hasfarm-holdings-425991/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/pag-pravesha-industries-426162/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/abb-second-pe-fund-426068/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/bain-capital-insignia-cc-capital-426023/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/india-healthcare-private-equity-425836/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kotak-fund-neuberg-diagnostics-425841/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/apollo-seven-i-buyout-425843/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/pe-vc-healthcare-investments-india-425705/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/gene-solutions-august-global-425694/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/blue-earth-secondaries-private-credit-425642/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/consortium-malaysia-airports-425648/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/botanic-healthcare-bags-funding-425629/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/quadria-capital-interview-2-425476/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/chinas-47b-third-semiconductor-big-fund-kickstarts-investments-425517/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/temasek-haldiram-425396/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kkr-said-to-be-weighing-sale-of-japans-seiyu-supermarket-425386/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/bain-capital-indonesia-424409/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/digital-edge-fresh-funding-425255/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/australias-insignia-financial-gets-1-8b-takeover-bid-from-cc-capital-partners-425233/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/norway-sovereign-wealth-fund-buys-45-stake-in-us-real-estate-portfolio-for-1b-425137/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/india-pe-vc-fundraising-2024-424684/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/creador-buys-mg-group-425038/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/mubadala-uae-pharma-firms-424968/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/eqt-temasek-to-sell-o2-power-to-jsw-neo-energy-for-1-5b-424789/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kkr-bain-bid-seven-i-assets-424701/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/top-pe-deals-india-2024-424555/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/sk-inc-sell-gas-unit-hahn-co-424657/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/prosus-to-buy-despegar-com-424652/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/singapore-talkmed-privatisation-424493/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/excelsior-capital-vietnam-second-fund-424451/\n",
      "✅ Scraped: Private equity firms pledge to be China-free as US tightens rules\n",
      "✅ Scraped: Top secondaries deals in Asia that marked PE landscape in 2024\n",
      "✅ Scraped: Creador secures $40m from FinDev Canada for sixth fund\n",
      "✅ Scraped: After Delhivery, Multiples backs another Indian logistics startup INSTANT-XP\n",
      "✅ Scraped: After Temasek, KKR backs Indian cloud kitchen startup Rebel Foods\n",
      "✅ Scraped: GLP Capital Partners bags $383m for latest China income fund\n",
      "✅ Scraped: PH Digest: Navegar exiting Royale Cold Storage; Pinnacle selling minority stake\n",
      "✅ Scraped: GIC invests another $150m in India's TPG-backed Asia Healthcare\n",
      "✅ Scraped: Bain's $1.7b offer rebuffed by Australia's Insignia on valuation concerns\n",
      "✅ Scraped: Fuji Soft sticks with KKR, rejects Bain's raised buyout offer\n",
      "🔄 'More' button clicked 5 times\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kedaara-impetus-426489/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/gaw-capital-agility-asset-advisers-426453/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/saarathi-finance-funding-426402/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/hkvca-asia-pe-forum-2025-426401/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/oriza-hua-debut-ma-fund-426223/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/tpg-hasfarm-holdings-425991/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/pag-pravesha-industries-426162/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/abb-second-pe-fund-426068/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/bain-capital-insignia-cc-capital-426023/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/india-healthcare-private-equity-425836/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kotak-fund-neuberg-diagnostics-425841/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/apollo-seven-i-buyout-425843/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/pe-vc-healthcare-investments-india-425705/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/gene-solutions-august-global-425694/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/blue-earth-secondaries-private-credit-425642/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/consortium-malaysia-airports-425648/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/botanic-healthcare-bags-funding-425629/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/quadria-capital-interview-2-425476/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/chinas-47b-third-semiconductor-big-fund-kickstarts-investments-425517/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/temasek-haldiram-425396/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kkr-said-to-be-weighing-sale-of-japans-seiyu-supermarket-425386/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/bain-capital-indonesia-424409/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/digital-edge-fresh-funding-425255/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/australias-insignia-financial-gets-1-8b-takeover-bid-from-cc-capital-partners-425233/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/norway-sovereign-wealth-fund-buys-45-stake-in-us-real-estate-portfolio-for-1b-425137/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/india-pe-vc-fundraising-2024-424684/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/creador-buys-mg-group-425038/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/mubadala-uae-pharma-firms-424968/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/eqt-temasek-to-sell-o2-power-to-jsw-neo-energy-for-1-5b-424789/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kkr-bain-bid-seven-i-assets-424701/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/top-pe-deals-india-2024-424555/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/sk-inc-sell-gas-unit-hahn-co-424657/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/prosus-to-buy-despegar-com-424652/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/singapore-talkmed-privatisation-424493/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/excelsior-capital-vietnam-second-fund-424451/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/private-equity-firms-may-not-invest-in-china-424339/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/top-asia-secondaries-deals-421780/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/creador-findev-canada-424316/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/multiples-backs-instant-xp-424292/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kkr-temasek-rebel-foods-424255/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/glp-capital-china-income-fund-2-424183/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/ph-digest-navegar-pinnacle-424142/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/gic-invests-in-asia-healthcare-424001/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/bain-insignia-valuation-concerns-423960/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/fuji-soft-kkr-buyout-offer-423943/\n",
      "✅ Scraped: Nuveen secures $100m private capital mandate from South Korean pension manager\n",
      "✅ Scraped: DEG commits $15m to Amicus Capital's second India fund\n",
      "✅ Scraped: Japanese cosmetics group Kose buys Lakeshore-backed skincare brand Panpuri\n",
      "✅ Scraped: Greater China Digest: I Squared mulls offer for HKBN; Beijing Tongyizhong to buy X-Fiper\n",
      "✅ Scraped: Five trends & strategies that will define Asia's PE landscape in 2025\n",
      "✅ Scraped: Bain Capital offers to buy Australia's Insignia Financial for $1.7b\n",
      "✅ Scraped: APAC may beat global markets in PE returns recovery: Preqin\n",
      "✅ Scraped: Bain, KKR, JIP advance to next round of bidding for Seven & i's non-core ops\n",
      "✅ Scraped: Orsted sells 50% stake in Greater Changhua 4 wind farm for $1.64bn\n",
      "✅ Scraped: Realistic expectations, ageing sponsor portfolios to propel SE Asia buyouts\n",
      "🔄 'More' button clicked 6 times\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kedaara-impetus-426489/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/gaw-capital-agility-asset-advisers-426453/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/saarathi-finance-funding-426402/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/hkvca-asia-pe-forum-2025-426401/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/oriza-hua-debut-ma-fund-426223/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/tpg-hasfarm-holdings-425991/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/pag-pravesha-industries-426162/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/abb-second-pe-fund-426068/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/bain-capital-insignia-cc-capital-426023/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/india-healthcare-private-equity-425836/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kotak-fund-neuberg-diagnostics-425841/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/apollo-seven-i-buyout-425843/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/pe-vc-healthcare-investments-india-425705/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/gene-solutions-august-global-425694/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/blue-earth-secondaries-private-credit-425642/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/consortium-malaysia-airports-425648/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/botanic-healthcare-bags-funding-425629/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/quadria-capital-interview-2-425476/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/chinas-47b-third-semiconductor-big-fund-kickstarts-investments-425517/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/temasek-haldiram-425396/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kkr-said-to-be-weighing-sale-of-japans-seiyu-supermarket-425386/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/bain-capital-indonesia-424409/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/digital-edge-fresh-funding-425255/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/australias-insignia-financial-gets-1-8b-takeover-bid-from-cc-capital-partners-425233/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/norway-sovereign-wealth-fund-buys-45-stake-in-us-real-estate-portfolio-for-1b-425137/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/india-pe-vc-fundraising-2024-424684/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/creador-buys-mg-group-425038/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/mubadala-uae-pharma-firms-424968/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/eqt-temasek-to-sell-o2-power-to-jsw-neo-energy-for-1-5b-424789/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kkr-bain-bid-seven-i-assets-424701/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/top-pe-deals-india-2024-424555/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/sk-inc-sell-gas-unit-hahn-co-424657/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/prosus-to-buy-despegar-com-424652/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/singapore-talkmed-privatisation-424493/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/excelsior-capital-vietnam-second-fund-424451/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/private-equity-firms-may-not-invest-in-china-424339/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/top-asia-secondaries-deals-421780/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/creador-findev-canada-424316/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/multiples-backs-instant-xp-424292/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kkr-temasek-rebel-foods-424255/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/glp-capital-china-income-fund-2-424183/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/ph-digest-navegar-pinnacle-424142/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/gic-invests-in-asia-healthcare-424001/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/bain-insignia-valuation-concerns-423960/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/fuji-soft-kkr-buyout-offer-423943/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/nuveen-korea-pension-manager-423844/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/deg-amicus-capital-india-fund-423812/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kose-panpuri-423807/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/i-squared-hkbn-beijing-tongyizhong-x-fiper-423340/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/five-pe-trends-strategies-for-2025-422552/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/insignia-financial-takeover-offer-bain-423369/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/apac-private-equity-performance-preqin-421350/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/bain-kkr-jip-seven-i-423147/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/orsted-sells-50-stake-in-greater-changhua-4-wind-farm-for-1-64bn-423024/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/private-equity-buyouts-2025-422526/\n",
      "✅ Scraped: Warburg expects uptick in PE deal activity in 2025 and 2026, says CEO Perlman\n",
      "✅ Scraped: India's Shubham Housing raises $118m led by Multiples PE\n",
      "✅ Scraped: Advantage Partners raises about 50% of Asia Fund II, to focus on SE Asia, India\n",
      "✅ Scraped: China's Goodix to acquire HongShan, Vertex-backed chip design unicorn Viewtrix\n",
      "✅ Scraped: Bain-backed IndiaRF takes controlling stake in Anthea Aromatics for $118m\n",
      "✅ Scraped: Growtheum Capital invests $121m in PH cold-chain firm Mets Logistics\n",
      "✅ Scraped: Indian PE Somerset Indus invests in Cyrix Healthcare\n",
      "✅ Scraped: Vietnam's Techcombank mulls stake sale, Warburg could weigh exit\n",
      "✅ Scraped: Healthcare, education lure investors in India, SE Asia, but exits hinge on value creation\n",
      "✅ Scraped: Quadria Capital extends final close of $800m healthcare fund\n",
      "🔄 'More' button clicked 7 times\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kedaara-impetus-426489/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/gaw-capital-agility-asset-advisers-426453/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/saarathi-finance-funding-426402/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/hkvca-asia-pe-forum-2025-426401/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/oriza-hua-debut-ma-fund-426223/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/tpg-hasfarm-holdings-425991/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/pag-pravesha-industries-426162/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/abb-second-pe-fund-426068/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/bain-capital-insignia-cc-capital-426023/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/india-healthcare-private-equity-425836/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kotak-fund-neuberg-diagnostics-425841/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/apollo-seven-i-buyout-425843/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/pe-vc-healthcare-investments-india-425705/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/gene-solutions-august-global-425694/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/blue-earth-secondaries-private-credit-425642/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/consortium-malaysia-airports-425648/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/botanic-healthcare-bags-funding-425629/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/quadria-capital-interview-2-425476/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/chinas-47b-third-semiconductor-big-fund-kickstarts-investments-425517/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/temasek-haldiram-425396/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kkr-said-to-be-weighing-sale-of-japans-seiyu-supermarket-425386/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/bain-capital-indonesia-424409/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/digital-edge-fresh-funding-425255/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/australias-insignia-financial-gets-1-8b-takeover-bid-from-cc-capital-partners-425233/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/norway-sovereign-wealth-fund-buys-45-stake-in-us-real-estate-portfolio-for-1b-425137/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/india-pe-vc-fundraising-2024-424684/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/creador-buys-mg-group-425038/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/mubadala-uae-pharma-firms-424968/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/eqt-temasek-to-sell-o2-power-to-jsw-neo-energy-for-1-5b-424789/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kkr-bain-bid-seven-i-assets-424701/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/top-pe-deals-india-2024-424555/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/sk-inc-sell-gas-unit-hahn-co-424657/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/prosus-to-buy-despegar-com-424652/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/singapore-talkmed-privatisation-424493/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/excelsior-capital-vietnam-second-fund-424451/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/private-equity-firms-may-not-invest-in-china-424339/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/top-asia-secondaries-deals-421780/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/creador-findev-canada-424316/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/multiples-backs-instant-xp-424292/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kkr-temasek-rebel-foods-424255/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/glp-capital-china-income-fund-2-424183/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/ph-digest-navegar-pinnacle-424142/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/gic-invests-in-asia-healthcare-424001/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/bain-insignia-valuation-concerns-423960/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/fuji-soft-kkr-buyout-offer-423943/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/nuveen-korea-pension-manager-423844/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/deg-amicus-capital-india-fund-423812/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kose-panpuri-423807/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/i-squared-hkbn-beijing-tongyizhong-x-fiper-423340/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/five-pe-trends-strategies-for-2025-422552/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/insignia-financial-takeover-offer-bain-423369/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/apac-private-equity-performance-preqin-421350/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/bain-kkr-jip-seven-i-423147/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/orsted-sells-50-stake-in-greater-changhua-4-wind-farm-for-1-64bn-423024/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/private-equity-buyouts-2025-422526/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/warburg-pincus-not-considering-ipo-422931/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/shubham-housing-finance-funding-422928/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/advantage-partners-second-apac-fund-422707/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/chinas-goodix-to-acquire-chip-design-unicorn-viewtrix-422692/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/indiarf-buys-anthea-aromatics-422672/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/growtheum-mets-logistics-422631/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/somerset-indus-cyrix-healthcare-422502/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/warburg-pincus-techcombank-422353/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/healthcare-education-lure-investors-420898/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/quadria-capital-asia-healthcare-fund-422095/\n",
      "✅ Scraped: Saudi Venture Capital invests in female-founded PE firm Aliph Capital\n",
      "✅ Scraped: Hedge fund Dymon Asia opens Dubai office, its first in the Middle East\n",
      "✅ Scraped: Nuveen makes $257m first close of Australian real estate debt strategy\n",
      "✅ Scraped: Chinese PE-VC investors try to find ‘sweet spot’ as reality hits home\n",
      "✅ Scraped: Insight Partners sells $2b stake in cloud data firm Veeam at $15b valuation\n",
      "✅ Scraped: Bain Capital invests $157m in Indonesia's Mayapada Hospital\n",
      "✅ Scraped: Growth, talent seen as key to sustaining Japan's private equity boom\n",
      "✅ Scraped: US investment firm Stonepeak launches infrastructure fund for HNIs\n",
      "✅ Scraped: TPG weighs $1.5b-plus sale of gym chain Crunch Fitness\n",
      "✅ Scraped: Bain-backed chipmaker Kioxia sets price range for Tokyo IPO: report\n",
      "🔄 'More' button clicked 8 times\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kedaara-impetus-426489/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/gaw-capital-agility-asset-advisers-426453/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/saarathi-finance-funding-426402/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/hkvca-asia-pe-forum-2025-426401/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/oriza-hua-debut-ma-fund-426223/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/tpg-hasfarm-holdings-425991/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/pag-pravesha-industries-426162/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/abb-second-pe-fund-426068/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/bain-capital-insignia-cc-capital-426023/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/india-healthcare-private-equity-425836/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kotak-fund-neuberg-diagnostics-425841/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/apollo-seven-i-buyout-425843/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/pe-vc-healthcare-investments-india-425705/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/gene-solutions-august-global-425694/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/blue-earth-secondaries-private-credit-425642/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/consortium-malaysia-airports-425648/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/botanic-healthcare-bags-funding-425629/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/quadria-capital-interview-2-425476/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/chinas-47b-third-semiconductor-big-fund-kickstarts-investments-425517/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/temasek-haldiram-425396/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kkr-said-to-be-weighing-sale-of-japans-seiyu-supermarket-425386/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/bain-capital-indonesia-424409/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/digital-edge-fresh-funding-425255/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/australias-insignia-financial-gets-1-8b-takeover-bid-from-cc-capital-partners-425233/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/norway-sovereign-wealth-fund-buys-45-stake-in-us-real-estate-portfolio-for-1b-425137/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/india-pe-vc-fundraising-2024-424684/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/creador-buys-mg-group-425038/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/mubadala-uae-pharma-firms-424968/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/eqt-temasek-to-sell-o2-power-to-jsw-neo-energy-for-1-5b-424789/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kkr-bain-bid-seven-i-assets-424701/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/top-pe-deals-india-2024-424555/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/sk-inc-sell-gas-unit-hahn-co-424657/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/prosus-to-buy-despegar-com-424652/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/singapore-talkmed-privatisation-424493/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/excelsior-capital-vietnam-second-fund-424451/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/private-equity-firms-may-not-invest-in-china-424339/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/top-asia-secondaries-deals-421780/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/creador-findev-canada-424316/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/multiples-backs-instant-xp-424292/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kkr-temasek-rebel-foods-424255/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/glp-capital-china-income-fund-2-424183/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/ph-digest-navegar-pinnacle-424142/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/gic-invests-in-asia-healthcare-424001/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/bain-insignia-valuation-concerns-423960/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/fuji-soft-kkr-buyout-offer-423943/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/nuveen-korea-pension-manager-423844/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/deg-amicus-capital-india-fund-423812/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kose-panpuri-423807/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/i-squared-hkbn-beijing-tongyizhong-x-fiper-423340/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/five-pe-trends-strategies-for-2025-422552/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/insignia-financial-takeover-offer-bain-423369/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/apac-private-equity-performance-preqin-421350/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/bain-kkr-jip-seven-i-423147/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/orsted-sells-50-stake-in-greater-changhua-4-wind-farm-for-1-64bn-423024/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/private-equity-buyouts-2025-422526/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/warburg-pincus-not-considering-ipo-422931/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/shubham-housing-finance-funding-422928/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/advantage-partners-second-apac-fund-422707/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/chinas-goodix-to-acquire-chip-design-unicorn-viewtrix-422692/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/indiarf-buys-anthea-aromatics-422672/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/growtheum-mets-logistics-422631/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/somerset-indus-cyrix-healthcare-422502/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/warburg-pincus-techcombank-422353/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/healthcare-education-lure-investors-420898/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/quadria-capital-asia-healthcare-fund-422095/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/saudi-venture-capital-aliph-capital-422326/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/dymon-asia-middle-east-office-422294/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/nuveen-australia-422285/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/china-pe-vc-industry-422002/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/insight-partners-veeam-422246/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/bain-capital-mayapada-hospital-422134/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/japan-private-equity-421560/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/us-investment-firm-stonepeak-launches-infrastructure-fund-for-hnis-422068/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/tpg-weighs-1-5b-plus-sale-of-gym-chain-crunch-fitness-422065/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kioxia-ipo-price-range-421791/\n",
      "✅ Scraped: How private equity navigated exit slowdown in SE Asia this year\n",
      "✅ Scraped: Warburg-backed consortium aims to seal ESR buyout soon\n",
      "✅ Scraped: BlackRock said to be in talks to buy private credit manager HPS\n",
      "✅ Scraped: KKR partners with Weave Living to invest in multi-family assets in Japan\n",
      "✅ Scraped: Fortress eyes Seven & i's supermarket operations\n",
      "✅ Scraped: CICC sets up second FoF to pool billions for China’s tech growth\n",
      "✅ Scraped: Affirma Capital sets around $350m target for debut India-focused fund\n",
      "✅ Scraped: PE Digest: Tata Capital Healthcare deploys 90% of Fund II, PAG may buy Manjushree Technopack\n",
      "✅ Scraped: US pension fund IMRF commits $100m to EQT's ninth Asia buyout vehicle\n",
      "✅ Scraped: Saudi Aramco unit in talks to invest $1b in US software maker Mavenir: report\n",
      "🔄 'More' button clicked 9 times\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kedaara-impetus-426489/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/gaw-capital-agility-asset-advisers-426453/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/saarathi-finance-funding-426402/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/hkvca-asia-pe-forum-2025-426401/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/oriza-hua-debut-ma-fund-426223/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/tpg-hasfarm-holdings-425991/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/pag-pravesha-industries-426162/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/abb-second-pe-fund-426068/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/bain-capital-insignia-cc-capital-426023/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/india-healthcare-private-equity-425836/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kotak-fund-neuberg-diagnostics-425841/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/apollo-seven-i-buyout-425843/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/pe-vc-healthcare-investments-india-425705/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/gene-solutions-august-global-425694/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/blue-earth-secondaries-private-credit-425642/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/consortium-malaysia-airports-425648/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/botanic-healthcare-bags-funding-425629/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/quadria-capital-interview-2-425476/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/chinas-47b-third-semiconductor-big-fund-kickstarts-investments-425517/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/temasek-haldiram-425396/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kkr-said-to-be-weighing-sale-of-japans-seiyu-supermarket-425386/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/bain-capital-indonesia-424409/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/digital-edge-fresh-funding-425255/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/australias-insignia-financial-gets-1-8b-takeover-bid-from-cc-capital-partners-425233/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/norway-sovereign-wealth-fund-buys-45-stake-in-us-real-estate-portfolio-for-1b-425137/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/india-pe-vc-fundraising-2024-424684/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/creador-buys-mg-group-425038/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/mubadala-uae-pharma-firms-424968/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/eqt-temasek-to-sell-o2-power-to-jsw-neo-energy-for-1-5b-424789/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kkr-bain-bid-seven-i-assets-424701/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/top-pe-deals-india-2024-424555/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/sk-inc-sell-gas-unit-hahn-co-424657/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/prosus-to-buy-despegar-com-424652/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/singapore-talkmed-privatisation-424493/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/excelsior-capital-vietnam-second-fund-424451/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/private-equity-firms-may-not-invest-in-china-424339/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/top-asia-secondaries-deals-421780/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/creador-findev-canada-424316/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/multiples-backs-instant-xp-424292/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kkr-temasek-rebel-foods-424255/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/glp-capital-china-income-fund-2-424183/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/ph-digest-navegar-pinnacle-424142/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/gic-invests-in-asia-healthcare-424001/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/bain-insignia-valuation-concerns-423960/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/fuji-soft-kkr-buyout-offer-423943/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/nuveen-korea-pension-manager-423844/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/deg-amicus-capital-india-fund-423812/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kose-panpuri-423807/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/i-squared-hkbn-beijing-tongyizhong-x-fiper-423340/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/five-pe-trends-strategies-for-2025-422552/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/insignia-financial-takeover-offer-bain-423369/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/apac-private-equity-performance-preqin-421350/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/bain-kkr-jip-seven-i-423147/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/orsted-sells-50-stake-in-greater-changhua-4-wind-farm-for-1-64bn-423024/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/private-equity-buyouts-2025-422526/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/warburg-pincus-not-considering-ipo-422931/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/shubham-housing-finance-funding-422928/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/advantage-partners-second-apac-fund-422707/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/chinas-goodix-to-acquire-chip-design-unicorn-viewtrix-422692/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/indiarf-buys-anthea-aromatics-422672/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/growtheum-mets-logistics-422631/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/somerset-indus-cyrix-healthcare-422502/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/warburg-pincus-techcombank-422353/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/healthcare-education-lure-investors-420898/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/quadria-capital-asia-healthcare-fund-422095/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/saudi-venture-capital-aliph-capital-422326/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/dymon-asia-middle-east-office-422294/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/nuveen-australia-422285/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/china-pe-vc-industry-422002/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/insight-partners-veeam-422246/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/bain-capital-mayapada-hospital-422134/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/japan-private-equity-421560/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/us-investment-firm-stonepeak-launches-infrastructure-fund-for-hnis-422068/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/tpg-weighs-1-5b-plus-sale-of-gym-chain-crunch-fitness-422065/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kioxia-ipo-price-range-421791/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/p-e-exits-se-asia-2024-419112/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/esr-buyout-421495/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/blackrock-said-to-be-in-talks-to-buy-private-credit-manager-hps-421411/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/kkr-weave-living-japan-421395/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/fortress-seven-supermarket-ops-421194/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/cicc-second-fof-421141/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/affirma-capital-first-india-fund-420977/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/tchf-ii-deployed-pag-may-buy-manjushree-technopack-420908/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/imrf-commits-to-bpea-fund-ix-420798/\n",
      "⚠️ Skipping already scraped article: https://www.dealstreetasia.com/stories/aramco-invest-in-mavenir-420823/\n",
      "✅ Scraped: Trustar raises $1b continuation vehicle to hold McDonald's China stake\n",
      "✅ Scraped: Navis Capital introduces new structure in second continuation fund\n",
      "✅ Scraped: Korea's Hanwha Life to acquire 75% of US financial firm Velocity Clearing\n",
      "✅ Scraped: Investors in Asia see ‘true alpha’ returns amid market volatility\n",
      "✅ Scraped: PE Digest: Gaja Capital eyes IPO; TA Associates invests in Vee Healthtek\n",
      "✅ Scraped: SG's CapitaLand picks up GP stakes in SC Capital Partners for $214m\n",
      "✅ Scraped: Hamilton Lane's Rogers sees mojo in China as foreign capital dries up\n",
      "🛑 Article 'Blackstone to buy majority stake in sandwich chain Jersey Mike's Subs' is older than 2 months. Stopping.\n",
      "✅ Scraped: Blackstone to buy majority stake in sandwich chain Jersey Mike's Subs\n"
     ]
    },
    {
     "ename": "MaxRetryError",
     "evalue": "HTTPConnectionPool(host='localhost', port=52468): Max retries exceeded with url: /session/240ff5f8ef01b39c8e332602e2a76fa1/back (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000272AADC4650>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Yibabe\\Desktop\\Scrapingproject\\venv\\Lib\\site-packages\\urllib3\\connection.py:198\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 198\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Yibabe\\Desktop\\Scrapingproject\\venv\\Lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yibabe\\Desktop\\Scrapingproject\\venv\\Lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Yibabe\\Desktop\\Scrapingproject\\venv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yibabe\\Desktop\\Scrapingproject\\venv\\Lib\\site-packages\\urllib3\\connectionpool.py:493\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 493\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yibabe\\Desktop\\Scrapingproject\\venv\\Lib\\site-packages\\urllib3\\connection.py:445\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[1;32m--> 445\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1331\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1091\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1091\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1094\u001b[0m \n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1035\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m-> 1035\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Yibabe\\Desktop\\Scrapingproject\\venv\\Lib\\site-packages\\urllib3\\connection.py:276\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yibabe\\Desktop\\Scrapingproject\\venv\\Lib\\site-packages\\urllib3\\connection.py:213\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    215\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    217\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp.client.connect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x00000272AADC4650>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 98\u001b[0m\n\u001b[0;32m     94\u001b[0m         scraped_urls\u001b[38;5;241m.\u001b[39madd(article_url)  \u001b[38;5;66;03m# Add to scraped URLs\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Scraped: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitle\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 98\u001b[0m     \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Go back to the main article page\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Wait before continuing\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (NoSuchElementException, StaleElementReferenceException) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Yibabe\\Desktop\\Scrapingproject\\venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:587\u001b[0m, in \u001b[0;36mWebDriver.back\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mback\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    580\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Goes one step backward in the browser history.\u001b[39;00m\n\u001b[0;32m    581\u001b[0m \n\u001b[0;32m    582\u001b[0m \u001b[38;5;124;03m    :Usage:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[38;5;124;03m            driver.back()\u001b[39;00m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 587\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGO_BACK\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Yibabe\\Desktop\\Scrapingproject\\venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:382\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m    380\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[1;32m--> 382\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[1;32mc:\\Users\\Yibabe\\Desktop\\Scrapingproject\\venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:404\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    402\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[0;32m    403\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[1;32m--> 404\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Yibabe\\Desktop\\Scrapingproject\\venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:428\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    425\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_config\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[1;32m--> 428\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    429\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Yibabe\\Desktop\\Scrapingproject\\venv\\Lib\\site-packages\\urllib3\\_request_methods.py:143\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[0;32m    136\u001b[0m         method,\n\u001b[0;32m    137\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw,\n\u001b[0;32m    141\u001b[0m     )\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Yibabe\\Desktop\\Scrapingproject\\venv\\Lib\\site-packages\\urllib3\\_request_methods.py:278\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, content_type)\n\u001b[0;32m    276\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> 278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Yibabe\\Desktop\\Scrapingproject\\venv\\Lib\\site-packages\\urllib3\\poolmanager.py:443\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    441\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 443\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32mc:\\Users\\Yibabe\\Desktop\\Scrapingproject\\venv\\Lib\\site-packages\\urllib3\\connectionpool.py:871\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[0;32m    867\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[0;32m    868\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    869\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    870\u001b[0m     )\n\u001b[1;32m--> 871\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    890\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[1;32mc:\\Users\\Yibabe\\Desktop\\Scrapingproject\\venv\\Lib\\site-packages\\urllib3\\connectionpool.py:871\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[0;32m    867\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[0;32m    868\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    869\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    870\u001b[0m     )\n\u001b[1;32m--> 871\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    890\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[1;32mc:\\Users\\Yibabe\\Desktop\\Scrapingproject\\venv\\Lib\\site-packages\\urllib3\\connectionpool.py:871\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[0;32m    867\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[0;32m    868\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    869\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    870\u001b[0m     )\n\u001b[1;32m--> 871\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    890\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[1;32mc:\\Users\\Yibabe\\Desktop\\Scrapingproject\\venv\\Lib\\site-packages\\urllib3\\connectionpool.py:841\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_e, (\u001b[38;5;167;01mOSError\u001b[39;00m, HTTPException)):\n\u001b[0;32m    839\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 841\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    844\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n\u001b[0;32m    846\u001b[0m \u001b[38;5;66;03m# Keep track of the error for the retry warning.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yibabe\\Desktop\\Scrapingproject\\venv\\Lib\\site-packages\\urllib3\\util\\retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[0;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[1;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_retry\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=52468): Max retries exceeded with url: /session/240ff5f8ef01b39c8e332602e2a76fa1/back (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000272AADC4650>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# =================== Helper Functions ===================\n",
    "\n",
    "def parse_date(date_text):\n",
    "    \"\"\"Convert date string to datetime object. Format: '16 January, 2025'\"\"\"\n",
    "    try:\n",
    "        return datetime.strptime(date_text, \"%d %B, %Y\")\n",
    "    except ValueError:\n",
    "        return None  # Return None if the format is incorrect\n",
    "\n",
    "def is_within_last_2_months(article_date):\n",
    "    \"\"\"Check if the article date is within the last 2 months\"\"\"\n",
    "    if article_date is None:\n",
    "        return False\n",
    "    today = datetime.today()\n",
    "    two_months_ago = today.replace(month=today.month - 2 if today.month > 2 else 12 + (today.month - 2), year=today.year if today.month > 2 else today.year - 1)\n",
    "    return article_date >= two_months_ago\n",
    "\n",
    "# =================== Selenium Setup ===================\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run in headless mode for efficiency\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Open the website\n",
    "url = \"https://www.dealstreetasia.com/section/private-equity\"\n",
    "driver.get(url)\n",
    "time.sleep(3)  # Allow page to load\n",
    "\n",
    "# Create CSV file and write header if not exists\n",
    "csv_filename = \"articles.csv\"\n",
    "scraped_urls = set()  # Track scraped URLs\n",
    "\n",
    "try:\n",
    "    with open(csv_filename, mode=\"r\", encoding=\"utf-8\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Skip header\n",
    "        for row in reader:\n",
    "            scraped_urls.add(row[4])  # Add existing URLs\n",
    "except FileNotFoundError:\n",
    "    with open(csv_filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Title\", \"Source\", \"Date\", \"Article\", \"URL\"])  # CSV Headers\n",
    "\n",
    "# =================== Scraping Logic ===================\n",
    "\n",
    "click_count = 0\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Wait for articles to load\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"archive-wrapper\"]/div[4]/div[1]/div/div')))\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error waiting for articles: {e}\")\n",
    "        break\n",
    "\n",
    "    # Get all articles on the current loaded page\n",
    "    articles = driver.find_elements(By.XPATH, '//*[@id=\"archive-wrapper\"]/div[4]/div[1]/div/div')\n",
    "\n",
    "    for index in range(len(articles)):  # Use index instead of directly iterating\n",
    "        try:\n",
    "            # Re-locate articles on each iteration to avoid stale references\n",
    "            articles = driver.find_elements(By.XPATH, '//*[@id=\"archive-wrapper\"]/div[4]/div[1]/div/div')\n",
    "            article = articles[index]\n",
    "\n",
    "            # Extract article link\n",
    "            link_element = article.find_element(By.XPATH, './/div[1]/a')\n",
    "            article_url = link_element.get_attribute(\"href\")\n",
    "\n",
    "            # ✅ **Skip if article is already scraped**\n",
    "            if article_url in scraped_urls:\n",
    "                print(f\"⚠️ Skipping already scraped article: {article_url}\")\n",
    "                continue\n",
    "\n",
    "            driver.execute_script(\"arguments[0].click();\", link_element)  # Click article link\n",
    "            time.sleep(1)  # Wait for article page to load\n",
    "\n",
    "            # Extract information\n",
    "            title = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"disable-copy\"]/h1'))).text\n",
    "            source = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[1]/div/div[1]/span/a').text\n",
    "            date_text = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[1]/div/div[1]/p').text\n",
    "            article_content = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[2]/div[1]/article').text\n",
    "\n",
    "            # Convert and check date\n",
    "            article_date = parse_date(date_text)\n",
    "            if not is_within_last_2_months(article_date):\n",
    "                print(f\"🛑 Article '{title}' is older than 2 months. Stopping.\")\n",
    "                driver.quit()\n",
    "                exit()\n",
    "\n",
    "            # Save article data\n",
    "            with open(csv_filename, mode=\"a\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([title, source, date_text, article_content, article_url])\n",
    "                scraped_urls.add(article_url)  # Add to scraped URLs\n",
    "\n",
    "            print(f\"✅ Scraped: {title}\")\n",
    "\n",
    "            driver.back()  # Go back to the main article page\n",
    "            time.sleep(2)  # Wait before continuing\n",
    "\n",
    "        except (NoSuchElementException, StaleElementReferenceException) as e:\n",
    "            print(f\"⚠️ Skipping article due to error: {e}\")\n",
    "            continue  # Skip and continue to the next article\n",
    "\n",
    "    # Try clicking the \"More\" button to load additional articles\n",
    "    try:\n",
    "        more_button = driver.find_element(By.XPATH, '//*[@id=\"archive-wrapper\"]/div[5]/div/button')\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", more_button)\n",
    "        time.sleep(4)\n",
    "        driver.execute_script(\"arguments[0].click();\", more_button)  # Click using JavaScript\n",
    "        time.sleep(5)  # Wait for new articles to load\n",
    "        click_count += 1\n",
    "        print(f\"🔄 'More' button clicked {click_count} times\")\n",
    "\n",
    "    except (NoSuchElementException, ElementClickInterceptedException):\n",
    "        print(\"⚠️ No 'More' button found or can't be clicked. Ending scrape.\")\n",
    "        break  # Stop clicking if the button is missing\n",
    "\n",
    "# Close browser\n",
    "driver.quit()\n",
    "print(\"\\n✅ Scraping complete! Data saved to 'news_articles.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setup Selenium WebDriver\n",
    "# chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
    "# service = Service(\"path/to/chromedriver\")  # Set correct path to chromedriver\n",
    "\n",
    "# driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# driver.get(\"https://www.dealstreetasia.com/section/private-equity\")\n",
    "# time.sleep(3)  # Allow time for page to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome() \n",
    "website=\"https://www.dealstreetasia.com/section/private-equity\"  \n",
    "driver.get(website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scraped: Indian PE giant Kedaara invests $350m in AI solution provider Impetus\n",
      "Error extracting article. Skipping...\n",
      "Error extracting article. Skipping...\n",
      "Error extracting article. Skipping...\n",
      "Error extracting article. Skipping...\n",
      "No 'More' button found. Scraping complete.\n",
      "Scraping finished.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Define CSV file\n",
    "csv_filename = \"scraped_articles.csv\"\n",
    "\n",
    "# Load already scraped URLs to prevent duplicates\n",
    "scraped_urls = set()\n",
    "if os.path.exists(csv_filename):\n",
    "    with open(csv_filename, \"r\", encoding=\"utf-8\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader, None)  # Skip header\n",
    "        for row in reader:\n",
    "            if row:\n",
    "                scraped_urls.add(row[3])  # Assuming URL is in the 4th column\n",
    "\n",
    "# Define stopping condition (articles older than 2 months)\n",
    "two_months_ago = datetime.now() - timedelta(days=60)\n",
    "\n",
    "# Open CSV file for writing\n",
    "with open(csv_filename, \"a\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    if os.stat(csv_filename).st_size == 0:\n",
    "        writer.writerow([\"Title\", \"Source\", \"Date\", \"URL\", \"Content\"])  # Write header if file is empty\n",
    "\n",
    "    while True:\n",
    "        articles = driver.find_elements(By.XPATH, \"//*[@id='archive-wrapper']/div[4]/div[1]/div/div\")\n",
    "        for article in articles:\n",
    "            try:\n",
    "                link_element = article.find_element(By.XPATH, \".//div[1]/a\")\n",
    "                url = link_element.get_attribute(\"href\")\n",
    "                \n",
    "                if url in scraped_urls:\n",
    "                    continue  # Skip already scraped articles\n",
    "                \n",
    "                link_element.click()\n",
    "                time.sleep(5)\n",
    "                \n",
    "                title = driver.find_element(By.XPATH, \"//*[@id='disable-copy']/h1\").text\n",
    "                source = driver.find_element(By.XPATH, \"//*[@id='disable-copy']/div[2]/div[1]/div/div[1]/span/a\").text\n",
    "                date_text = driver.find_element(By.XPATH, \"//*[@id='disable-copy']/div[2]/div[1]/div/div[1]/p\").text\n",
    "                content = driver.find_element(By.XPATH, \"//*[@id='disable-copy']/div[2]/div[2]/div[1]/article\").text\n",
    "                \n",
    "                # Convert date to datetime object\n",
    "                date_obj = datetime.strptime(date_text, \"%d %B, %Y\")\n",
    "                if date_obj < two_months_ago:\n",
    "                    print(\"Reached articles older than 2 months. Stopping...\")\n",
    "                    driver.quit()\n",
    "                    exit()\n",
    "                \n",
    "                writer.writerow([title, source, date_text, url, content])\n",
    "                scraped_urls.add(url)\n",
    "                print(f\"✅ Scraped: {title}\")\n",
    "                driver.back()\n",
    "                time.sleep(4)\n",
    "            \n",
    "            except (NoSuchElementException, StaleElementReferenceException):\n",
    "                print(\"Error extracting article. Skipping...\")\n",
    "                driver.back()\n",
    "                time.sleep(4)\n",
    "                continue\n",
    "        \n",
    "        # Click 'More' button if available\n",
    "        try:\n",
    "            more_button = driver.find_element(By.XPATH, \"//*[@id='archive-wrapper']/div[5]/div/button\")\n",
    "            driver.execute_script(\"arguments[0].click();\", more_button)\n",
    "            time.sleep(5)\n",
    "        except NoSuchElementException:\n",
    "            print(\"No 'More' button found. Scraping complete.\")\n",
    "            break\n",
    "\n",
    "print(\"Scraping finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open the target website\n",
    "# url = \"https://www.dealstreetasia.com/section/private-equity\"\n",
    "# driver.get(url)\n",
    "# time.sleep(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open the target website\n",
    "# url = \"https://www.dealstreetasia.com/section/private-equity\"\n",
    "# driver.get(url)\n",
    "# time.sleep(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//*[@id=\"archive-wrapper\"]/div[5]/div\n",
    "\n",
    "\n",
    "//*[@id=\"archive-wrapper\"]/div[4]\n",
    "//*[@id=\"archive-wrapper\"]/div[5]\n",
    "//*[@id=\"archive-wrapper\"]/div[5]/div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up Selenium WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run headless for efficiency\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Open the target website\n",
    "url = \"https://www.dealstreetasia.com/section/private-equity\"\n",
    "driver.get(url)\n",
    "time.sleep(2)  # Allow page to load\n",
    "\n",
    "# Set date threshold (2 months ago)\n",
    "two_months_ago = datetime.now() - timedelta(days=2 * 30)  # Approximate 2 months\n",
    "\n",
    "\n",
    "# Set date threshold (2 months ago)\n",
    "two_months_ago = datetime.now() - timedelta(days=2 * 30)  # Approximate 2 months\n",
    "\n",
    "# Open CSV file for writing\n",
    "csv_filename = \"2_months.csv\"\n",
    "with open(csv_filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Source\", \"Date\", \"Article Content\", \"URL\"])  # CSV Headers\n",
    "\n",
    "    click_count = 0  # Track \"More\" button clicks\n",
    "    stop_scraping = False  # Stop when we find old articles\n",
    "\n",
    "    while click_count < 5:  # Max 5 times\n",
    "        print(f\"\\n🔍 Scraping articles from current page (Click count: {click_count})...\\n\")\n",
    "        \n",
    "        # Extract article links from the current page\n",
    "        articles = driver.find_elements(By.XPATH, '//*[@id=\"archive-wrapper\"]/div[4]/div[1]/div/div')\n",
    "        article_links = [article.find_element(By.XPATH, './div[1]/a').get_attribute('href') for article in articles]\n",
    "\n",
    "        for link in article_links:\n",
    "            driver.get(link)\n",
    "            time.sleep(1)  \n",
    "\n",
    "            try:\n",
    "                title = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/h1').text.strip()\n",
    "                source = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[1]/div/div[1]/span/a').text.strip()\n",
    "                date_text = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[1]/div/div[1]/p').text.strip()\n",
    "                body = driver.find_element(By.XPATH, '//*[@id=\"disable-copy\"]/div[2]/div[2]/div[1]/article').text.strip().replace(\"\\n\", \" \")  \n",
    "\n",
    "                # Convert date format\n",
    "                try:\n",
    "                    article_date = datetime.strptime(date_text, \"%d %B, %Y\")\n",
    "                except ValueError:\n",
    "                    print(f\"Skipping article with invalid date format: {date_text}\")\n",
    "                    continue  \n",
    "\n",
    "                # Stop if article is older than 2 months\n",
    "                if article_date < two_months_ago:\n",
    "                    print(f\"⛔ Stopping: Found old article {title} ({article_date.strftime('%Y-%m-%d')})\")\n",
    "                    stop_scraping = True\n",
    "                    break  \n",
    "\n",
    "                # Save data to CSV\n",
    "                writer.writerow([title, source, article_date.strftime(\"%Y-%m-%d\"), body, link])\n",
    "                print(f\"✅ Saved: {title} ({article_date.strftime('%Y-%m-%d')})\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error extracting data from {link}: {e}\")\n",
    "\n",
    "            if stop_scraping:\n",
    "                break  # Stop scraping if we hit an old article\n",
    "\n",
    "        if stop_scraping:\n",
    "            break  # Stop if we reached an old article\n",
    "\n",
    "        # Try to click the \"More\" button\n",
    "        try:\n",
    "            more_button = driver.find_element(By.XPATH, '//*[@id=\"archive-wrapper\"]/div[5]/div/button')\n",
    "            driver.execute_script(\"arguments[0].click();\", more_button)  # Click using JavaScript\n",
    "            time.sleep(3)  # Wait for new articles to load\n",
    "            click_count += 1\n",
    "            print(f\"\\n🔄 'More' button clicked {click_count} times\\n\")\n",
    "\n",
    "        except (NoSuchElementException, ElementClickInterceptedException):\n",
    "            print(\"\\n⚠️ No more 'More' button found. Stopping scraping.\\n\")\n",
    "            break  # Stop if the button is missing or can't be clicked\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "print(f\"\\n✅ Scraping complete! Data saved to {csv_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
